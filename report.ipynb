{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabriel Lluch\n",
    "CS 598 - PSL\n",
    "660131202\n",
    "\n",
    "# Project 3 - Report\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Sentiment Classification Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Report\n",
    "\n",
    "### Overview\n",
    "\n",
    "The sentiment classification process leveraged the provided **OpenAI embeddings** as direct input to a classification model, bypassing traditional natural language processing steps such as tokenization, bag-of-words encoding, or manual feature engineering. Since the embeddings already captured semantic and contextual nuances of the reviews, this approach streamlined sentiment modeling. However, this method traded off interpretability for high performance, as discussed in the next section.\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "Data preparation involved extracting the **1,536-dimensional OpenAI-generated embeddings** from the given training and test splits. These features were standardized using a `StandardScaler` to ensure uniform weighting and stable optimization during training. Importantly, the scaler was fit only on the training set to prevent data leakage. \n",
    "\n",
    "**Logistic Regression** with elastic-net regularization was chosen for its simplicity, coefficient-level interpretability, and robustness to high-dimensional data. Hyperparameters, including the regularization strength (`C`) and `l1_ratio`, were tuned via cross-validation (`LogisticRegressionCV`) on the training split. Values of `C = 0.01` and `l1_ratio = 0.1` were determined sufficient to meet performance benchmarks, balancing bias and variance across multiple folds.\n",
    "\n",
    "### Training and Evaluation\n",
    "\n",
    "Once optimal hyperparameters were identified, they were consistently applied across all splits to ensure straightforward reproducibility and consistent model behavior. The training procedure across each split followed a uniform methodology:\n",
    "1. Load data.\n",
    "2. Standardize embeddings.\n",
    "3. Fit the logistic regression model.\n",
    "4. Predict probabilities for the test set.\n",
    "\n",
    "This approach ensured fair comparisons of performance metrics (AUC scores) across all five provided splits.\n",
    "\n",
    "Predictions for each test split were saved into `mysubmission.csv` to adhere to the project’s submission requirements. The simplicity of the approach, combined with the direct use of pre-computed embeddings, facilitated efficient training and inference while achieving high AUC scores across all splits.\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "| **Split** | **Test AUC** | **Execution Time (s)** |\n",
    "|-----------|--------------|-------------------------|\n",
    "| 1         | 0.986928     | 24.05                  |\n",
    "| 2         | 0.986612     | 27.56                  |\n",
    "| 3         | 0.986332     | 24.39                  |\n",
    "| 4         | 0.986937     | 26.87                  |\n",
    "| 5         | 0.986216     | 26.39                  |\n",
    "| **Avg**   | **0.986605** | **25.85**              |\n",
    "\n",
    "\n",
    "## Hardware Specifications\n",
    "\n",
    "- **Device:** Apple M3 Pro  \n",
    "- **RAM:** 36GB  \n",
    "- **Operating System:** MacOS 14.3  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Model Interpretability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability Approach\n",
    "\n",
    "To understand which parts of the review text most strongly influence the model’s sentiment predictions, we implemented a **sentence-level interpretability technique** on a subset of test reviews from the first split. We selected **five positive** and **five negative reviews**, ensuring a balanced perspective on how the model perceives both sentiment classes.\n",
    "\n",
    "The approach is based on an **embedding alignment model** to align both review-level and sentence-level embeddings with the model's input space. We performed two key analyses to interpret sentiment predictions:\n",
    "\n",
    "1. **Individual Sentence Analysis:** Assigning sentiment scores to individual sentences.\n",
    "2. **Leave-One-Out Analysis:** Quantifying the importance of each sentence by observing the impact of its removal on the overall sentiment prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Sentence Extraction and Embedding Alignment\n",
    "\n",
    "### Preprocessing, Tokenization, Encoding Strategy\n",
    "\n",
    "- For training the **alignment mechanism**, the workflow involves embedding **entire reviews** (not individual sentences) using **BERT**. These embeddings represent the full semantic structure of the review in a **768-dimensional space**, aligned with corresponding **1,536-dimensional OpenAI embeddings**.\n",
    "\n",
    "- Each full review undergoes preprocessing before embedding:\n",
    "  - **HTML tags** are removed using BeautifulSoup.\n",
    "  - **URLs** are replaced with placeholders to ensure uniformity.\n",
    "  - Non-printable characters and excess whitespace are eliminated.\n",
    "  - The cleaned reviews are embedded as a whole using BERT.\n",
    "\n",
    "- For interpretability using sentence-level analysis on the selected reviews:\n",
    "  - The reviews are **tokenized into individual sentences** using **nltk's sentence tokenizer**.\n",
    "  - Sentence embeddings are generated for each sentence in the selected reviews using BERT. These embeddings are transformed to the OpenAI embedding space using the trained alignment mechanism.\n",
    "  - This process allows for sentence-specific sentiment scoring, providing a fine-grained understanding of how individual sentences contribute to the overall sentiment.\n",
    "\n",
    "- For interpretability using **leave-one-out analysis** on the selected reviews:\n",
    "  - For each sample review, the overall sentiment score is computed using the full review embedding.\n",
    "  - Each sentence is then omitted one at a time, and the remaining text is re-embedded to compute the updated sentiment score.\n",
    "  - The change in sentiment score when a sentence is removed quantifies the **influence of that sentence** on the model's prediction.\n",
    "  - Sentences whose presence causes the largest increase in sentiment score are identified as **key positive contributors**, while those whose presence decreases the score are identified as **key negative drivers**.\n",
    "\n",
    "This dual approach of **sentence-specific scoring** and **leave-one-out analysis** offers complementary insights into how individual sentences shape the sentiment predictions, enhancing the interpretability of the model's decision-making process.\n",
    "\n",
    "#### Sentence Embedding with BERT\n",
    "- For each tokenized sentence:\n",
    "  - Sentence embeddings are generated using the **[CLS] token representation** from a pre-trained **BERT base model (base-uncased)**.\n",
    "  - Longer reviews are split into manageable chunks of up to 510 tokens to ensure compatibility with BERT's input size limitations. The resulting embeddings for all chunks are **averaged** to form the final representation.\n",
    "- BERT embeddings are **768-dimensional**, capturing semantic nuances at the sentence level.\n",
    "\n",
    "#### Alignment to OpenAI Embedding Space\n",
    "- Since our sentiment classification model operates in the **OpenAI embedding space (1,536 dimensions)**, the BERT embeddings must be aligned to this higher-dimensional space:\n",
    "  1. **Scaling BERT Embeddings:** The generated BERT embeddings are scaled using a **StandardScaler**, fit on training data, to normalize feature distributions.\n",
    "  2. **Linear Regression Mapping:** A **linear regression alignment model** transforms the scaled 768-dimensional BERT embeddings into the 1,536-dimensional OpenAI space.\n",
    "\n",
    "#### Evaluation of Alignment Approaches\n",
    "- To determine the optimal alignment approach, we experimented with several models, including:\n",
    "  - **Linear Models:** Lasso, Ridge, ElasticNet.\n",
    "  - **Tree-Based Models:** RandomForest, XGBoost.\n",
    "  - **Neural Network Architectures:** Simple feedforward networks with varying depths and activation functions.\n",
    "\n",
    "- While more complex models occasionally improved certain metrics, they often severely compromised others, such as cosine similarity or interpretability. In contrast, **basic LinearRegression** offered a straightforward and robust solution, achieving:\n",
    "  - **R² Score:** 0.35\n",
    "  - **Cosine Similarity:** 0.77\n",
    "  - **Mean Squared Error (MSE):** 0.00027\n",
    "\n",
    "#### Consistency and Reproducibility\n",
    "- While this notebook contains code to process and train the alignment model from scratch, to ensure consistency, the trained scaler and alignment model can be loaded directly from a **GitHub**.\n",
    "- The alignment model provides a semantically meaningful mapping to the OpenAI embedding space, suitable for input into the logistic regression sentiment classifier.\n",
    "\n",
    "This preprocessing and embedding alignment workflow bridges the dimensional and representational gap between BERT and OpenAI embeddings while ensuring solid performance metrics with a simple and efficient alignment model.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Sentence-Level Sentiment Scoring for Sample Reviews\n",
    "\n",
    "- After mapping each sentence’s BERT embedding to its corresponding OpenAI embedding, we passed these embeddings through the **trained logistic regression sentiment classifier**.\n",
    "- This process yielded a **probability score** for each sentence, offering a fine-grained view of its sentiment.\n",
    "- For visualization, sentences were **color-coded** in the original review text:\n",
    "  - **Positive Sentences:** Greenish hues.\n",
    "  - **Negative Sentences:** Red or orange tones.\n",
    "\n",
    "This color-coding made it intuitive to identify which sentences most influenced the overall sentiment prediction. We see that then positive reviews are dominated by green while negative reviews are dominated by red,\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Leave-One-Out Analysis\n",
    "\n",
    "To use a different approach to measure the importance of individual sentences, we performed a **leave-one-out analysis**:\n",
    "\n",
    "1. Computed the model’s sentiment probability for the full review.\n",
    "2. For each sentence:\n",
    "   - Removed the sentence from the review.\n",
    "   - Re-embedded the modified text using the same **BERT and alignment pipelines**.\n",
    "   - Re-ran the classifier on the modified embedding to observe changes in sentiment probability.\n",
    "3. Measured the **difference in sentiment score** before and after removing each sentence.\n",
    "\n",
    "#### Insights from Leave-One-Out Analysis\n",
    "- Sentences whose removal caused large **drops in sentiment scores** were identified as key **positive contributors**.\n",
    "- Sentences whose removal led to an **increase in sentiment scores** were identified as key **negative drivers**.\n",
    "\n",
    "- Similar to the direct sentence embedding approach, we also list the sentences by order of their leave-one-out impact, from positive to negative impact.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Observations and Insights\n",
    "\n",
    "By combining **color-coded visualizations** and **leave-one-out analysis**, we uncovered valuable insights into the model’s decision-making process.  \n",
    "Please refer to the end of this file to view the results of color coding analysis, and sentence impact magnitidude ordering for both approaches.\n",
    "\n",
    "### General Trends in Sentiment Scoring\n",
    "- The **sentence-specific scoring** and **leave-one-out analysis** revealed that positive reviews are typically dominated by **positive sentences**, while negative reviews are dominated by **negative sentences**. This pattern indicates the model’s ability to capture sentiment trends at the sentence level in alignment with the overall review sentiment.\n",
    "\n",
    "### Misclassifications and Ambiguities in Individual Sentence Analysis\n",
    "However, there are notable cases where the sentence-level predictions diverge from the review sentiment:\n",
    "\n",
    "1. **Incorrectly Marked Positive Sentiment in Negative Reviews:**\n",
    "   - Example: *\"Sadly, the film suffers from difficult to believe characters as well as a major plot problem that makes some of the characters seem brain-addled.\"*\n",
    "     - This sentence is incorrectly marked as **positive**, likely due to specific phrases or words that the model interprets in isolation without understanding the full negative context.\n",
    "   - Common Issue: Sentences describing **positive actions or events in a movie** are often marked positive, even when the author’s opinion is negative.\n",
    "\n",
    "2. **Incorrectly Marked Negative Sentiment in Positive Reviews:**\n",
    "   - Example: *\"Disgusted by the state of karate, Oyama returns to his lone training.\"*\n",
    "     - This sentence is incorrectly marked as **negative** in an otherwise positive review. The model’s misclassification likely stems from the word *\"disgusted,\"* which is contextually negative but not indicative of the review's sentiment. Given that it's merely describing a point in the plot, a score closer to neutral would be more appropriate.\n",
    "   - Example: *\"Just plain old great television.\"*\n",
    "     - This sentence is incorrectly marked as **negative**, likely because the model misinterprets *\"plain old\"* as a negative sentiment phrase. However, the overall context and the word *\"great\"* clearly signal positivity. This misclassification demonstrates the model’s difficulty in handling nuanced expressions, where certain words may carry sentiment depending on context and phrasing.\n",
    "\n",
    "### Correctly Classified Sentences\n",
    "Despite misclassifications, many sentences are correctly classified, aligning with the sentiment of the review:\n",
    "\n",
    "1. **Negative Sentiment in a Negative Review:**\n",
    "   - Example: *\"No resolution or big twist or anything.\"*\n",
    "     - This sentence is correctly identified as **negative**, highlighting dissatisfaction and critique of the subject.\n",
    "   \n",
    "2. **Positive Sentiment in a Positive Review:**\n",
    "   - Example: *\"This is a tragic love story and a refreshing entry into the genre.\"*\n",
    "     - The sentence is correctly marked as **positive**, emphasizing the author’s praise for the movie.\n",
    "\n",
    "### Magnitudes and Consistency in Analysis\n",
    "- While there are differences in **magnitude** and **ordering** between the single-sentence scoring and leave-one-out analysis, the results are **largely consistent** with the overall sentiment predictions.\n",
    "- Single-sentence scoring provides an isolated sentiment view, whereas leave-one-out analysis highlights the **contribution** of each sentence to the overall sentiment. These two approaches complement each other, offering both granular and holistic insights.\n",
    "\n",
    "### Leave-One-Out Analysis\n",
    "Leave-one-out analysis highlights the influence of individual sentences on the overall sentiment of a review. While this approach captures contextual dependencies, it also reveals cases where the sentence impacts diverge from the expected sentiment alignment:\n",
    "\n",
    "1. **Positive Influence in Negative Reviews:**\n",
    "   - Example (Review 19238, Negative Review): \n",
    "     - *\"But at least there's enough neat carnival themes and b-movie monster makeup to keep you watching.\"*  \n",
    "       This sentence is marked as having a **positive influence** on the overall score. Though the review sentiment is negative, this sentence offers some positive slant in that the movie has some entertaining aspects.\n",
    "   \n",
    "   - Example (Review 15808, Negative Review): \n",
    "     - *\"Everything is so very peachy and swell--the family adores Bergman and things couldn't be more perfect.\"*  \n",
    "       This sentence contributes positively to the sentiment, likely due to the phrases \"peachy and swell\" and \"things couldn't be more perfect.\" However, in the context of the review, these descriptions could be sarcastic, and the sentence's impact should be neutral or even negative.\n",
    "\n",
    "2. **Negative Influence in Positive Reviews:**\n",
    "   - Sentences with a neutral or mildly negative tone (e.g., plot descriptions or critical observations) in positive reviews can lower the sentiment score disproportionately. For instance:\n",
    "     - A sentence like *\"The pacing was slow at times, but the story made up for it\"* could contribute negatively due to the phrase \"slow at times,\" even though the sentence ends positively.\n",
    "\n",
    "3. **Ambiguity in Neutral Sentences:**\n",
    "   - Example (Review 23733, Negative Review): \n",
    "     - Neutral sentences like *\"Family goes away on vacation and 16-year-old daughter wants independence from parents.\"* are marked with a **positive or negative influence** depending on how the model interprets the surrounding context. This demonstrates how leave-one-out analysis sometimes amplifies subtle shifts in sentiment, even for sentences that seem purely descriptive.\n",
    "\n",
    "---\n",
    "\n",
    "### Explanatory Considerations\n",
    "- **Model Tendency Toward Keywords Over Context:**\n",
    "  - The model often emphasizes specific keywords or phrases, which can lead to misclassifications. For example:\n",
    "    - Words like *\"tragic\"* or *\"disgusted\"* are strongly associated with sentiment polarity, even when their contextual meaning may differ.\n",
    "    - Phrases like *\"plain old great television\"* are misinterpreted due to an overreliance on the phrase *\"plain old\"* as a negative cue, despite the positive intent.\n",
    "\n",
    "- **Contextual Dependencies in Leave-One-Out Analysis:**\n",
    "  - Leave-one-out analysis reveals that the model incorporates some level of **sentence interdependencies**, as removing a sentence can significantly alter the overall sentiment score.\n",
    "  - However, this also exposes limitations:\n",
    "    - Neutral or descriptive sentences may have exaggerated impacts due to their balancing role in the review.\n",
    "    - Mixed-sentiment reviews, where both positive and negative aspects are discussed, often show sentences contributing in unexpected directions.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Insights\n",
    "1. **Alignment of Overall Trends:**\n",
    "   - Positive reviews are generally dominated by positive sentences, and negative reviews by negative ones. This alignment shows the model’s capability to broadly capture sentiment trends.\n",
    "\n",
    "2. **Nuances and Misclassifications:**\n",
    "   - Misclassifications often occur when:\n",
    "     - Sentences describe **events or actions** (e.g., plot details) that don't directly reflect the author’s sentiment.\n",
    "     - The model focuses on isolated keywords rather than contextual meaning.\n",
    "   - For instance, sarcasm or complex expressions are frequently misinterpreted due to a lack of deeper semantic understanding.\n",
    "\n",
    "3. **Complementary Analyses:**\n",
    "   - Combining **single-sentence scoring** with **leave-one-out analysis** provides a more holistic view of how individual sentences shape sentiment predictions:\n",
    "     - Single-sentence scoring highlights isolated sentiment polarity.\n",
    "     - Leave-one-out analysis captures the contribution of each sentence to the overall sentiment, revealing interdependencies and contextual nuances.\n",
    "\n",
    "4. **Model Limitations:**\n",
    "   - The model’s overemphasis on specific words and its inability to fully account for sarcasm, nuanced expressions, or mixed sentiment reviews highlight areas for improvement.\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations and Trade-Offs\n",
    "While the interpretability approach offers valuable insights, it comes with several challenges:\n",
    "\n",
    "1. **Noise in Embedding Alignment:**\n",
    "   - Mapping BERT embeddings to OpenAI’s space introduces potential noise, which may slightly distort the semantic fidelity of sentence representations.\n",
    "\n",
    "2. **Resource Intensity:**\n",
    "   - Leave-one-out analysis is computationally expensive, requiring multiple re-embedding operations. This could limit scalability in large datasets or real-time applications.\n",
    "\n",
    "3. **Contextual Shifts:**\n",
    "   - Removing sentences during leave-one-out analysis can unintentionally shift the review’s overall context, leading to misleading interpretations of sentence contributions.\n",
    "\n",
    "4. **Handling Mixed Sentiment:**\n",
    "   - Reviews with balanced positive and negative observations challenge the model, as it struggles to weigh these nuances accurately in both single-sentence scoring and leave-one-out approaches.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "The combined use of **sentence-specific scoring** and **leave-one-out analysis** offers a detailed and complementary understanding of sentiment predictions. This approach provides a **clearer window into embedding-based models**, highlighting the textual elements most influential to predictions while exposing key limitations:\n",
    "\n",
    "- **Strengths:** These methods excel at identifying and visualizing how individual sentences contribute to overall sentiment, providing interpretable insights for model evaluation.\n",
    "- **Weaknesses:** The reliance on specific keywords and computational intensity limits scalability and accuracy in nuanced cases, such as sarcasm or mixed sentiment.\n",
    "\n",
    "Despite its imperfections, this interpretability framework advances the understanding of sentiment models by uncovering the **underlying decision-making process**. Future enhancements could include:\n",
    "- Incorporating attention mechanisms to better capture sentence-level dependencies.\n",
    "- Differentiating factual from opinion-based sentences to reduce misclassification in descriptive contexts.\n",
    "- Exploring alternative embedding alignment techniques to improve semantic fidelity.\n",
    "\n",
    "Ultimately, this analysis not only enhances trust in the model’s predictions but also highlights critical areas for refinement, paving the way for more robust and interpretable sentiment classification systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'sentiment', 'review', 'embedding_1', 'embedding_2',\n",
      "       'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6',\n",
      "       'embedding_7',\n",
      "       ...\n",
      "       'embedding_1527', 'embedding_1528', 'embedding_1529', 'embedding_1530',\n",
      "       'embedding_1531', 'embedding_1532', 'embedding_1533', 'embedding_1534',\n",
      "       'embedding_1535', 'embedding_1536'],\n",
      "      dtype='object', length=1539)\n",
      "Index(['id', 'sentiment', 'review', 'embedding_1', 'embedding_2',\n",
      "       'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6',\n",
      "       'embedding_7',\n",
      "       ...\n",
      "       'embedding_1527', 'embedding_1528', 'embedding_1529', 'embedding_1530',\n",
      "       'embedding_1531', 'embedding_1532', 'embedding_1533', 'embedding_1534',\n",
      "       'embedding_1535', 'embedding_1536'],\n",
      "      dtype='object', length=1539)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Selecting Reviews\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Set random seed\n",
    "random.seed(42)\n",
    "\n",
    "# Load data for split 1\n",
    "train_data = pd.read_csv('data/split_1/train.csv')\n",
    "test_data = pd.read_csv('data/split_1/test.csv')\n",
    "test_labels = pd.read_csv('data/split_1/test_y.csv')\n",
    "\n",
    "# Merge test data and labels\n",
    "test_data = test_data.merge(test_labels, on='id')\n",
    "\n",
    "# Separate positive and negative reviews\n",
    "positive_reviews = test_data[test_data['sentiment'] == 1]\n",
    "negative_reviews = test_data[test_data['sentiment'] == 0]\n",
    "\n",
    "# Randomly select 5 positive and 5 negative reviews\n",
    "selected_positive = positive_reviews.sample(n=5, random_state=42)\n",
    "selected_negative = negative_reviews.sample(n=5, random_state=42)\n",
    "\n",
    "# Combine selected reviews\n",
    "selected_reviews = pd.concat([selected_positive, selected_negative])\n",
    "\n",
    "# Reorder test columns for alignment\n",
    "test_data= test_data[train_data.columns]\n",
    "print(train_data.columns)\n",
    "print(test_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to load resources from GitHub\n",
    "import joblib\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def load_from_github(url):\n",
    "    \"\"\"\n",
    "    Load a file from a given GitHub raw content URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Downloading from {url}...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        loaded_object = joblib.load(BytesIO(response.content))\n",
    "        print(\"Download and loading successful.\")\n",
    "        return loaded_object\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gabriellluch/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gabriellluch/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/gabriellluch/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/gabriellluch/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Splitting Reviews into Sentences\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(selected_reviews.iloc[0]['review'])\n",
    "selected_reviews['sentences'] = selected_reviews['review'].apply(\n",
    "    lambda x: sent_tokenize(x) if isinstance(x, str) else []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic preprocessing\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = clean_html(text)\n",
    "    # Replace URLs\n",
    "    text = replace_urls(text)\n",
    "    # Normalize whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    # Remove non-printable characters\n",
    "    text = ''.join(filter(lambda x: x in string.printable, text))\n",
    "    return text\n",
    "\n",
    "def clean_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "def replace_urls(text):\n",
    "    url_pattern = r'http\\S+|www.\\S+'\n",
    "    return re.sub(url_pattern, '<URL>', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellluch/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Define BERT model and embedding utilities\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Sentence level embedding\n",
    "def get_sentence_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    # Get the [CLS] token embedding\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    return cls_embedding.flatten()\n",
    "\n",
    "def get_review_embedding(review_text, tokenizer, bert_model, device, chunk_size=510):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive BERT embedding for a full review by splitting it into chunks.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(review_text)\n",
    "    chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size)]\n",
    "    embeddings = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk_text = tokenizer.convert_tokens_to_string(chunk)\n",
    "        inputs = tokenizer(chunk_text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy().flatten()\n",
    "        embeddings.append(cls_embedding)\n",
    "\n",
    "    if embeddings:\n",
    "        # Aggregate embeddings (e.g., average)\n",
    "        review_embedding = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        # Handle empty reviews\n",
    "        review_embedding = np.zeros(bert_model.config.hidden_size)\n",
    "\n",
    "    return review_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert reviews to their BERT embeddings\n",
    "import joblib\n",
    "bert_train_path = \"bert_train\"\n",
    "openai_train_path = \"openai_train\"\n",
    "\n",
    "# THIS STEP IS USED TO CONVERT REVIEWS TO BERT EMBEDDINGS IN ORDER TO TRAIN ALIGNMENT MODEL\n",
    "# THIS STEP CAN BE SKIPPED BY LOADING THE TRAINED MODEL DIRECTLY FROM GITHUB\n",
    "# UNCOMMENT IF YOU WOULD LIKE TO CREATE THE EMBEDDED REVIEWS LOCALLY\n",
    "\n",
    "EMBED_REVIEWS = False\n",
    "\n",
    "if EMBED_REVIEWS:\n",
    "    # Number of samples to use for mapping\n",
    "    n_samples = 25000\n",
    "\n",
    "    # Randomly select reviews from training data\n",
    "    # mapping_samples = train_data.sample(n=n_samples, random_state=42)\n",
    "\n",
    "    mapping_samples = train_data.copy()\n",
    "    bert_embeddings = []\n",
    "\n",
    "    for review in mapping_samples['review']:\n",
    "        clean_review = preprocess_text(review)\n",
    "        bert_emb = get_review_embedding(clean_review, tokenizer, bert_model, device)\n",
    "        bert_embeddings.append(bert_emb)\n",
    "\n",
    "    bert_embeddings = np.array(bert_embeddings)\n",
    "    # Get OpenAI embeddings from training data\n",
    "    openai_embeddings = mapping_samples.iloc[:, 3:].values\n",
    "\n",
    "    # Save embedding data\n",
    "    joblib.dump(bert_embeddings, 'bert_train')\n",
    "    joblib.dump(openai_embeddings, 'openai_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_train shape: (25000, 768)\n",
      "openai_train shape: (25000, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Load saved embedding data\n",
    "bert_embeddings = joblib.load(bert_train_path)\n",
    "openai_embeddings = joblib.load(openai_train_path)\n",
    "\n",
    "# Verify shapes\n",
    "print(\"bert_train shape:\", bert_embeddings.shape)\n",
    "print(\"openai_train shape:\", openai_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://raw.githubusercontent.com/gclluch/psl_project_3/main/bert_scaler.pkl...\n",
      "Download and loading successful.\n"
     ]
    }
   ],
   "source": [
    "# Fit the BERT input scaler or load from remote\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# URL to the scaler file on GitHub\n",
    "bert_scaler_url = \"https://raw.githubusercontent.com/gclluch/psl_project_3/main/bert_scaler.pkl\"\n",
    "\n",
    "FETCH_BERT_SCALER = True\n",
    "\n",
    "if FETCH_BERT_SCALER:\n",
    "    bert_scaler = load_from_github(bert_scaler_url)\n",
    "else:\n",
    "    # Train a new scaler if loading is not required\n",
    "    print(\"Fitting a new scaler...\")\n",
    "    bert_scaler = StandardScaler()\n",
    "    bert_scaler.fit(bert_embeddings)  # Fit on training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://raw.githubusercontent.com/gclluch/psl_project_3/main/alignment_model.pkl...\n",
      "Download and loading successful.\n",
      "R^2 score of the Linear Regression: 0.3497796544637562\n",
      "MSE score of the Linear Regression 0.0002662521497447378\n",
      "Cosing Similarity score of the Linear Regression 0.7689253035754772\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train LinearRegression embedding alignment model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# URL to the LinReg alignment file on GitHub\n",
    "alignment_model_url = \"https://raw.githubusercontent.com/gclluch/psl_project_3/main/alignment_model.pkl\"\n",
    "\n",
    "FETCH_ALIGNMENT_MODEL = True\n",
    "if FETCH_ALIGNMENT_MODEL:\n",
    "    # Load the trained alignment model from GitHub\n",
    "    lin_reg = load_from_github(alignment_model_url)\n",
    "    print(\"R^2 score of the Linear Regression: 0.3497796544637562\")\n",
    "    print(\"MSE score of the Linear Regression 0.0002662521497447378\")\n",
    "    print(\"Cosing Similarity score of the Linear Regression 0.7689253035754772\")\n",
    "else:\n",
    "    # Apply the scaler\n",
    "    bert_embeddings_scaled = bert_scaler.transform(bert_embeddings)\n",
    "\n",
    "    # Fit linear regression model\n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    lin_reg.fit(bert_embeddings_scaled, openai_embeddings)\n",
    "    r2_score = lin_reg.score(bert_embeddings_scaled, openai_embeddings)\n",
    "    print(f'R^2 score of the Linear Regression: {r2_score}')\n",
    "    joblib.dump(lin_reg, 'lin_reg_model.pkl')\n",
    "\n",
    "    lin_reg_predictions = lin_reg.predict(bert_embeddings_scaled)\n",
    "    lin_reg_mse = mean_squared_error(openai_embeddings, lin_reg_predictions)\n",
    "    lin_reg_cos_sim = np.mean([\n",
    "        cosine_similarity(\n",
    "            [openai_embeddings[i]], [lin_reg_predictions[i]])[0, 0]\n",
    "            for i in range(len(openai_embeddings))\n",
    "            ])\n",
    "\n",
    "    print('MSE score of the Linear Regression', lin_reg_mse)\n",
    "    print('Cosing Similarity score of the Linear Regression', lin_reg_cos_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/71tlkgvn0nq_lc2l08scf5000000gn/T/ipykernel_6497/4044260249.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "/var/folders/gd/71tlkgvn0nq_lc2l08scf5000000gn/T/ipykernel_6497/4044260249.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "/var/folders/gd/71tlkgvn0nq_lc2l08scf5000000gn/T/ipykernel_6497/4044260249.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "/var/folders/gd/71tlkgvn0nq_lc2l08scf5000000gn/T/ipykernel_6497/4044260249.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "/var/folders/gd/71tlkgvn0nq_lc2l08scf5000000gn/T/ipykernel_6497/4044260249.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "/var/folders/gd/71tlkgvn0nq_lc2l08scf5000000gn/T/ipykernel_6497/4044260249.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "/var/folders/gd/71tlkgvn0nq_lc2l08scf5000000gn/T/ipykernel_6497/4044260249.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Transforming Sentence Embeddings to OpenAI format\n",
    "\n",
    "selected_reviews['sentence_embeddings'] = None\n",
    "for idx, row in selected_reviews.iterrows():\n",
    "    sentence_embeddings = []\n",
    "    for sentence in row['sentences']:\n",
    "        # Use BERT to get embedding of single sentence\n",
    "        clean_review = preprocess_text(sentence)\n",
    "        bert_emb = get_review_embedding(clean_review, tokenizer, bert_model, device)\n",
    "        bert_emb_reshaped = bert_emb.reshape(1, -1)\n",
    "\n",
    "        # Transform BERT -> OpenAI using the learned mapping\n",
    "        scaled_emb = bert_scaler.transform(bert_emb_reshaped)\n",
    "        openai_emb = lin_reg.predict(scaled_emb)\n",
    "\n",
    "        openai_emb_list = openai_emb.tolist()\n",
    "        sentence_embeddings.append(openai_emb_list)\n",
    "\n",
    "    # Store the transformed embeddings\n",
    "    selected_reviews.at[idx, 'sentence_embeddings'] = sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://raw.githubusercontent.com/gclluch/psl_project_3/main/sentiment_model.pkl...\n",
      "Download and loading successful.\n",
      "Downloading from https://raw.githubusercontent.com/gclluch/psl_project_3/main/sentiment_scaler.pkl...\n",
      "Download and loading successful.\n",
      "Sentiment model and scaler loaded successfully from GitHub.\n",
      "Classifier and scaler loaded successfully.\n",
      "LogisticRegression(C=0.01, l1_ratio=0.1, max_iter=10000, penalty='elasticnet',\n",
      "                   random_state=42, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Sentiment analysis for individual sentences in selected reviews\n",
    "\n",
    "# URLs for the sentiment model and scaler files on GitHub\n",
    "model_url = \"https://raw.githubusercontent.com/gclluch/psl_project_3/main/sentiment_model.pkl\"\n",
    "scaler_url = \"https://raw.githubusercontent.com/gclluch/psl_project_3/main/sentiment_scaler.pkl\"\n",
    "\n",
    "# Load the sentiment model and scaler\n",
    "logreg_sentiment_model = load_from_github(model_url)\n",
    "logreg_sentiment_scaler = load_from_github(scaler_url)\n",
    "\n",
    "# Confirm successful loading\n",
    "if logreg_sentiment_model and logreg_sentiment_scaler:\n",
    "    print(\"Sentiment model and scaler loaded successfully from GitHub.\")\n",
    "else:\n",
    "    print(\"Failed to load sentiment model or scaler.\")\n",
    "\n",
    "print(\"Classifier and scaler loaded successfully.\")\n",
    "print(logreg_sentiment_model)\n",
    "\n",
    "selected_reviews['sentence_scores'] = None\n",
    "# For each review\n",
    "for idx, row in selected_reviews.iterrows():\n",
    "    sentence_scores = []\n",
    "    for emb in row['sentence_embeddings']:\n",
    "        emb_np = np.array(emb)\n",
    "\n",
    "        # Scale the input embedding\n",
    "        emb_scaled = logreg_sentiment_scaler.transform(emb_np.reshape(1, -1))\n",
    "\n",
    "        # Generate sentence sentiment score\n",
    "        prob = logreg_sentiment_model.predict_proba(emb_scaled)[0, 1]\n",
    "\n",
    "        sentence_scores.append(prob)\n",
    "\n",
    "    selected_reviews.at[idx, 'sentence_scores'] = sentence_scores\n",
    "\n",
    "# selected_reviews['sentence_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/71tlkgvn0nq_lc2l08scf5000000gn/T/ipykernel_6497/1278788734.py:3: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:grey\">Well, I fear that my review of this special won't heed much different observation than the others before me, but I literally just watched it- during a PBS membership drive- and frankly I'm too excited NOT to say anything.</span> <span style=\"color:limegreen\">To really appreciate the enigma that is Barbra Streisand, you have to look back before the movies.</span> <span style=\"color:chartreuse\">Before the Broadway phenomenon of the mid-60's.</span> <span style=\"color:chartreuse\">When television was still a young medium, there was a form of entertainment very prominent on the air that is but a memory today: musical variety.</span> <span style=\"color:chartreuse\">Some musical shows were weekly series, but others were single, one-time specials, usually showcasing the special talent of the individual performer.</span> <span style=\"color:chartreuse\">This is where we get the raw, uninhibited first looks at Streisand.</span> <span style=\"color:grey\">She had already been a guest performer on other variety shows including Garry Moore, Ed Sullivan, and scored a major coup in a one-time only tandem appearance with the woman who would pass her the baton of belter extraordinary: Judy Garland.</span> <span style=\"color:chartreuse\">In 1966, COLOR ME BARBRA introduced Barbra Streisand in color (hence the title), but copied the format of her first special a year earlier almost to the letter.</span> <span style=\"color:yellow\">In 3 distinct acts, we get an abstract Streisand (in an after-hours art museum looking at and sometimes becoming the works of art), a comic Streisand working an already adoring audience in a studio circus (populated with many fuzzy and furry animals), and best of all, a singing Streisand in mini-concert format just-- well, frankly, just doing it.</span> <span style=\"color:chartreuse\"><br /><br />It amazes me that she still had the film debut of FUNNY GIRL yet to come, as well as turns as songwriter, director, and political activist.</span> <span style=\"color:yellowgreen\">Here, she is barely 24 years old, doing extraordinary things because, as she puts it in her own on-camera introduction, 'we didn't know we couldn't, so we did.'</span> <span style=\"color:red\">The art museum sequence is shot in Philadelphia over one weekend immediately after the museum closed to the public on Saturday evening, and apparently done with only ONE color camera.</span> <span style=\"color:grey\">Yet there are cuts, dissolves, and tracking shots galore, resulting in one rather spectacular peak moment-- the modern, slightly beatnik-flavored, \\Gotta Move.\\\" After getting lost amongst the modern abstracts, jazz-club bongos begin, with Streisand emerging in a psychedelic gown and glittering eye makeup, doing the catchy staccato tune with almost androgynous sex appeal.</span> <span style=\"color:chartreuse\">It is not until Act 3, believe it or not, that the moment is matched or bettered by another feat: in the concert sequence, in a white gown and pearl earrings, Streisand recites the torchy \\\"Any Place I Hang My Hat is Home,\\\" tearing into the final notes and revealing one of those climactic belts that makes you scream like a little girl even if you're 44 years old...and a guy.</span> <span style=\"color:red\">Just plain old great television.</span> <span style=\"color:chartreuse\">Check it out.\"</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:grey\">What happens when the average joe finds out he has supernatural powers?</span> <span style=\"color:orange\">The premise may sound familiar.</span> <span style=\"color:limegreen\">The Watchmen?</span> <span style=\"color:chartreuse\">Unbreakable?</span> <span style=\"color:yellowgreen\">However, the Russian sci-fi action flick, The Sword Bearer, is far from the standard stock.<br /><br />The story revolves around a man named Sasha who as a boy was shunned from society, his peers and family due to a supernatural power that he possess.</span> <span style=\"color:chartreuse\">When he wishes or his anger allows, a sword extends from his arm piercing his own skin.</span> <span style=\"color:red\">Very wolverinish?</span> <span style=\"color:red\">Maybe... but that's not the interesting part of this film.</span> <span style=\"color:grey\">Shunned all his life and driven by anger (and a temper he does have) our \\hero\\\" returns to his home town to turn his life around or find a reason to.</span> <span style=\"color:red\">The only thing he encounters here is trouble when an encounter with an old flame's new boyfriend leaves him bloodied on the ground.</span> <span style=\"color:chartreuse\">This is where the vengeance and anger comes into play.</span> <span style=\"color:yellow\">This is a man you do not want to cross and from this point the mafia and the police are on his tail.</span> <span style=\"color:chartreuse\">He meets a girl and falls in love instantly as does she and this is really what the movie is about.<br /><br />The film is highly impressionistic with bold colors and noir overtones spliced with short yet extreme action sequences.</span> <span style=\"color:limegreen\">This is art house at it's core, beautifully filmed with such attention to details in every scene over gruesome sci-fi action.</span> <span style=\"color:chartreuse\">It's this odd mash that interests me so much in this film.</span> <span style=\"color:chartreuse\">The directors approach for this genre is refreshing focusing on the emotional journey of Sasha and not a straight action film.</span> <span style=\"color:chartreuse\">Don't worry though, the action is there and plenty of it.</span> <span style=\"color:yellow\">However, much of these sequences show only implied violence with pictures of the horrific aftermath.</span> <span style=\"color:chartreuse\">This is not to say that action is not shown.</span> <span style=\"color:chartreuse\">These scenes are here and are fantastic (especially the ending where we see Sasha's full powers unleashed in desperation).</span> <span style=\"color:orange\">The director chooses to imply the violence of many scenes to keep the focus on the character's emotional struggle at hand.</span> <span style=\"color:chartreuse\">This is a tragic love story and a refreshing entry into the genre.\"</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:limegreen\">For years i've had a distant memory of watching this film , i looked on the net to find it somewhere and couldn't find it anywhere so i thought it must have disappeared.<br /><br />UNTIL...my gran showed me a box set she sent off for in the Daily Mail and i though nah there wont be anything decent in there, but to my great surprise there amongst other gems was The Water Babies!</span> <span style=\"color:red\">I hadn't been that excited ina long long time!</span> <span style=\"color:chartreuse\">Its a great light hearted film, the songs aren't memorable probably if i was a child during the time it came out i would have stuck in my mind more.</span> <span style=\"color:yellow\">Sadly it was just a film i watched at my grans 10 years ago when i was a little spud.</span> <span style=\"color:red\">And watching it back now the animation is terrible!</span> <span style=\"color:red\">and the re-recored voices they do to get a richness to the sound in films is totally off!</span> <span style=\"color:grey\">But who cares when your a kid you never think of those things, even if they lead boy is about 10 and sounds like a boy in the middle of puberty.<br /><br />Great classic kids film!</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:chartreuse\">This film is a brilliant retelling of Shakespeare's classic love story, complete with \\kinky sex, body piercing, and dismemberment\\\".</span> <span style=\"color:limegreen\">It does follow the same spirit as all the other Troma movies [except Combat Shock...That sucker was depressing] but it's not only for Troma fans.</span> <span style=\"color:yellow\">Anybody who appreciates lowbrow visuals and a hilarious script will without a doubt fall in love with this movie.<br /><br />Don't expect pretentious, artistic-wannabe crap like the version of R&J with Claire Danes and Leo DiCaprio; this one knows its a silly movie and draws its humor from that.</span> <span style=\"color:grey\">The acting is also surprisingly good, and you can just feel Sammy Capulet's pain as he tries to put his brain back into his head.<br /><br />The soundtrack, which contains many original and high-energy bands like The Wesley Willis Fiasco, Supernova, and The Meatmen is also four-star.</span> <span style=\"color:limegreen\">This movie should be viewed by all, because it remains faithful to the original story while still being jam-packed with Troma's trademark gore/sex humor.\"</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:chartreuse\">Mas Oyama was the most successful karate master of the late 20th century.</span> <span style=\"color:red\">He rejected the \\training\\\" of the karate clubs of the time focusing on an intense no holds form of training.</span> <span style=\"color:chartreuse\">He eventually built his system into a huge business empire with hundreds of schools across the world, without compromising his teachings.</span> <span style=\"color:chartreuse\">The testing in the Kyokushin schools are still some of the most physically challenging tests any martial art school requires.</span> <span style=\"color:yellow\">One non- physical hardship Oyama faced was prejudice due to his Korean ancestry and he spent time proving that loyalties were to Japan and Japanese Karate.</span> <span style=\"color:chartreuse\">This movie series was part of that effort although anyone who had the chance to meet Oyama (I did) would never question his allegiance to Japan.</span> <span style=\"color:chartreuse\">In this series, Oyama's most famous student, Sonny Chiba, is called upon to portray his master.<br /><br />Oyama arrives from the countryside where he has been training alone.</span> <span style=\"color:yellowgreen\">He challenges and makes short work of the established Karate schools he encounters.</span> <span style=\"color:red\">Disgusted by the state of karate, Oyama returns to his lone training.</span> <span style=\"color:yellowgreen\">He eventually picks up a student, falls in love and gets in the way of gangsters who are allied with the established karate schools.</span> <span style=\"color:limegreen\">In the middle of this is the legendary bullfight with a mad bull.</span> <span style=\"color:yellow\">How much of the film is true is questionable.<br /><br />That Oyama could kill a bull with his bare hands is true.</span> <span style=\"color:chartreuse\">He was called on to repeat this feat numerous times.</span> <span style=\"color:chartreuse\">There are filmed instances of Oyama actually doing this, although sometimes the bulls seemed to be tethered as Oyama was getting on in years.</span> <span style=\"color:chartreuse\">Sonny Chiba portrays his master with conviction and the karate is quite good.</span> <span style=\"color:yellowgreen\">Chiba may not have been the best karate practitioner but, at this point in time, he was certainly above average.</span> <span style=\"color:limegreen\"><br /><br />As a whole the movie is good, much better then most martial art films in the drama department.</span> <span style=\"color:chartreuse\">I always wondered why it's not more well known.</span> <span style=\"color:chartreuse\">Possibly it the very realistic depictions of martial arts.</span> <span style=\"color:chartreuse\">People are shown getting tired and hurt unlike 99% of action film where the hero is a limitless fountain of energy and each blow instantly dispatches an opponent to death.</span> <span style=\"color:orange\">Chiba seems so exhausted at one point that it hurts to watch.</span> <span style=\"color:chartreuse\">Perhaps viewers rather not have their entertainment reflect reality so closely.<br /><br />Recommended especially for martial artists.\"</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:yellow\">I'm a huge fan of both Emily Watson (Breaking The Waves) and Tom Wilkinson (Normal) and was amused to see them upstaged by Rupert Everett (Dellamorte Dellamore) in this shockingly rather minor movie that had all the ingredients to be so much more.</span> <span style=\"color:red\">The too brief scenes in which he portrays a languid, infinitely entitled, worthless son of a rich Lord are spot-on and entertaining.</span> <span style=\"color:red\">But for a love triangle there was remarkably little chemistry to speak of between anyone.</span> <span style=\"color:red\">The music was annoyingly movie-of-the-week quality, and the voice-over jarring and totally unnecessary.</span> <span style=\"color:red\">Clearly the work of a first-time director with a small budget who either lacked or didn't sufficiently heed good advice.</span> <span style=\"color:chartreuse\">Too bad.<br /><br />I can appreciate how the people you kind of hate at the beginning are the ones you kind of like at the end, and vice-versa, so there is some sort of character arc, at least in terms of perception.</span> <span style=\"color:chartreuse\">For example, Watson's character, while refreshingly honest to her husband about her feelings for another man, began to grate on me near the end, particularly when she announced to her husband that she simply had absolutely no control over her actions, and later when she simply declared that she would be moving back into their marital flat, with no asking of permission, no apologies offered.</span> <span style=\"color:red\">And I went from disliking Wilkinson's control freak / moral relativist character to sort of understanding him and not really wanting him to change (unlike his wife).<br /><br />This movie awkwardly morphed from a whodunit to a \\Love Story\\\" or \\\"Steel Magnolias\\\" illness drama without sufficiently informing me of the fact, so I was left distractedly guessing what the next plot twist might be long after they had all been revealed (Was it the Lord driving the car?</span> <span style=\"color:yellow\">The Lord's dog?).</span> <span style=\"color:chartreuse\">The scene where the Lord visits Wilkinson and relates how brave Watson is, the bestest nurse any dying boyfriend could ever ask for, Florence Nightingale incarnate, etc.</span> <span style=\"color:orange\">was OK until he started over-the-top sobbing like a baby.</span> <span style=\"color:limegreen\">Good God!</span> <span style=\"color:red\">If you ask me she's just another flitty rich person with way too much time on her hands, and so she drives her hard working, well providing spouse crazy with unnecessary drama.</span> <span style=\"color:red\">Her screwing around was just another way to occupy her empty life; the dying guy thing was an added bonus for her as it somehow made her previous actions completely above reproach.<br /><br />Look, everyone would have been better off if Wilkinson had just left her for his secretary, who seemed to appreciate him for who he was.</span> <span style=\"color:red\">Instead he acted like an abused dog, his open craving for his wife's affection increasing with every kick she gives him.</span> <span style=\"color:chartreuse\">I'm not anti PC or anything, it just didn't ring true, even after taking into account all of the harsh realities of middle age we all tend to face.</span> <span style=\"color:red\">The ending for me was (and not the director's intention I am certain) depressing.</span> <span style=\"color:red\">The movie spent the last 80 minutes convincing me that these two people just don't belong together, so I found no joy in the promise of their relationship continuing.</span> <span style=\"color:limegreen\">I'm not above wanting my emotions manipulated by a story, it just has to be somewhat plausible and not hackneyed.</span> <span style=\"color:orange\">Is that asking too much?<br /><br />My score: 4/10\"</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:yellowgreen\">Alan (Anthony Steffen), an English multi-millionaire with a few screws loose (thanks to his first wife's infidelity and untimely death during childbirth), entices sexy, red-headed women to his castle, offering them bundles of cash to stay the weekend.</span> <span style=\"color:yellow\">Once back at his ancestral pile, he gets them nekkid, proceeds to flog them with a bull-whip, and then kills them.<br /><br />But when he meets blonde hottie Gladys (Marina Malfatti) and falls for her ample charms, he decides to give up his murderous ways and get married.</span> <span style=\"color:orange\">Their wedded bliss is short-lived, however, thanks to Alan's iffy mental state, which becomes increasingly fragile when his dead wife Evelyn starts to appear outside his window and a spate of gruesome murders occur within the castle grounds.<br /><br />So let's recap: a groovy 70s Euro-horror with loads of tasty women in various states of undress; spooky Gothic retreats and misty graveyards; a sadistic rich psycho with a penchant for drop-dead gorgeous babes with cracking bods; several vicious murders (including a great bit where one victim has her head bashed in with a rock and her entrails eaten by foxes).</span> <span style=\"color:red\">Normally, a checklist like that would guarantee me a good timeso why did I find 'The Night Evelyn Came Out Of Her Grave' so dull?</span> <span style=\"color:red\">Well, for starters, the plot is way too convoluted: there are red herrings, crazy plot developments, and suspects galore, and it all becomes a bit too much.</span> <span style=\"color:red\">By the ridiculous endingin which we discover that, all along, several people have been plotting to get their greedy paws on Alan's wealth, and that our red-head killing nut-job is actually supposed to be the hero of the moviemy head was hurting too much to care!</span> <span style=\"color:red\">Secondly, Emilio Maraglia's direction is pretty torpid.</span> <span style=\"color:red\">Stylish, yes; but as slow as molasses at times.<br /><br />And then there's the bits that are just too damn silly, possibly even for a giallo: the death by poisonous snake bite (surely one of the most bizarre choices of weapon ever); Alan's Aunt Agatha, an old crippled relative who is played by a pretty young woman; the hiring of a group of identical curly headed blondes as maids; the poor attempt at convincing the audience that the film is set in England (mentioning 'pounds' and hiring a crap police uniform for one of the extras is not enough); and then, of course, there is the unlikelihood of finding a bag of sulphuric acid laying next to a swimming pool...<br /><br />'The Night Evelyn Came Out Of Her Grave' isn't a total waste of time (how could it be, with so much female flesh on show?</span><span style=\"color:chartreuse\">), but there are much better giallo's out there.</span> <span style=\"color:chartreuse\">Watch this one if you're a fan of the genre and you've already seen the bestbut don't expect too much.</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:red\">This is what Disney Channel shows to kids who are dumber than posts.</span> <span style=\"color:chartreuse\">It suits them well.</span> <span style=\"color:red\">It's not funny, the acting is the worst I've seen in many years, there are more stereotypes than there are actors, and everything about this show makes you groan and roll your eyes.</span> <span style=\"color:limegreen\">Wanna know why?</span> <span style=\"color:red\">Not only is this show a waste of airtime, the lead \\actress\\\" Selena Gomez looks like a pig.</span> <span style=\"color:yellow\">Jake T. Austin's character needs some Ritalin.</span> <span style=\"color:red\">David Henrie's character needs to visit a strip club and get wasted.</span> <span style=\"color:red\">Also, the writer of the show is inconsistent.</span> <span style=\"color:grey\">In one episode, the security guard is called \\\"sir\\\" by one character and referred to as a woman by all else.</span> <span style=\"color:limegreen\"><br /><br />Hello?</span> <span style=\"color:chartreuse\">It's called proofreading and editing.</span> <span style=\"color:limegreen\">Do it sometime, Disney.</span> <span style=\"color:limegreen\"><br /><br />Has anyone seen the promo for the new \\\"four part bloodsucking saga\\\"?</span> <span style=\"color:grey\">Disney wanted their own version of the Twilight vs. Harry Potter thing.</span> <span style=\"color:yellow\">Except a million times lamer.</span> <span style=\"color:limegreen\">The Wizards of Waverly Place Movie??</span> <span style=\"color:grey\">Think about it for a minute.</span> <span style=\"color:chartreuse\">Family goes away on vacation and 16 year old daughter wants independence from parents.</span> <span style=\"color:red\">SAME PLOT from The Proud Family Movie etc...<br /><br />What's worse is all the Emmies and ALMA'S it got.</span> <span style=\"color:orange\">And most of the audience are some-what age's 4-13 (And no life teenagers).</span> <span style=\"color:yellow\">how many more years?</span> <span style=\"color:red\">before selena gomez is showing her tits?<br /><br />and Disney shows are all crap..hack writers..hack shows..destroying the minds and wallets of today's youth..\"</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:grey\">You'd think that with Ingrid Bergman and Warner Baxter that this film would have been a lot better.</span> <span style=\"color:limegreen\">Sadly, the film suffers from difficult to believe characters as well as a major plot problem that makes some of the characters seem brain-addled.<br /><br />The film begins with Ingrid Bergman coming to work for the Stoddard family.</span> <span style=\"color:chartreuse\">Everything is so very peachy and swell--the family adores Bergman and things couldn't be more perfect.</span> <span style=\"color:grey\">Well, that is until the mother (Fay Wray) dies, the stock market crashes in 1907 (wiping out the family's fortune) and Bergman is forced to go back home to France.</span> <span style=\"color:chartreuse\">This portion of the film is a bit sticky sweet, but not bad.<br /><br />Later, after the family's fortunes have improved, Bergman returns.</span> <span style=\"color:red\">The four boys are now all grown and there isn't really a conceivable reason why they'd hire her once again as a governess.</span> <span style=\"color:chartreuse\">But, briefly, everything is swell once again.</span> <span style=\"color:yellowgreen\">But, when WWI occurs, the four all go to war--gosh!</span> <span style=\"color:chartreuse\">In the midst of this, one of the sons (David) brings home his new wife (Susan Hayward).</span> <span style=\"color:chartreuse\">Miss Hayward's character is as black and white as the others, though while they are all good and swell, she's obviously a horny she-devil.</span> <span style=\"color:red\">To make things worse, she comes to live in the family home while David is at war.<br /><br />Now here is where the movie gets really, really dumb--brain-achingly dumb.</span> <span style=\"color:chartreuse\">Hayward begins an affair with one of David's brothers but when the father sees a silhouette of the lovers, Bergman enters the room from another entrance and pretends that it was her, not Hayward with Jack!</span> <span style=\"color:red\">WHY?!</span> <span style=\"color:red\">Why would any sane person do this to save the butt of an obviously evil and conniving woman?</span> <span style=\"color:red\">This was exactly the sort of excuse Bergman needed to get rid of the gutter-snipe once and for all!</span> <span style=\"color:red\">This is just a case of lousy writing and made me mad...and most likely did the same to the audiences back in 1941.<br /><br />The rest of the movie consists of failed opportunity after failed opportunity for Hayward's evilness to be exposed.</span> <span style=\"color:red\">This just flies against common sense and made the film a silly melodramatic mess.</span> <span style=\"color:red\">As expected, however, the truth eventually comes out and everyone is swell once again---happy to be one big loving wonderful family minus the slut, Hayward.<br /><br />The film suffers because of poor writing.</span> <span style=\"color:yellow\">Hayward's affair made no sense--at least in how it was handled.</span> <span style=\"color:red\">And, having characters who are so gosh-darn good or evil (with nothing in between) sinks this movie to the level of a second-rate soap.</span> <span style=\"color:red\">The only thing that saves it at all is the acting---they tried as best they could with a turgid script.</span> <span style=\"color:red\">Suffice to say that the Columbia Pictures writers who did this film should have been slapped with a dead chicken!</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span style=\"color:limegreen\">Someone else called this film a \\fable-horror\\\" movie, and I think that fits pretty well.</span> <span style=\"color:yellowgreen\">That's the concept at least.</span> <span style=\"color:yellow\">A group of teenagers, each with their own vice, catch the eye of a twisted sideshow barker.</span> <span style=\"color:chartreuse\">He decides to teach the teens a lesson by making them part of the freak show.</span> <span style=\"color:yellow\">A cool idea, but could have been executed better.</span> <span style=\"color:yellow\">The fate for some of the teens is shoved in your face too obviously, while other characters could have been fleshed out more.</span> <span style=\"color:orange\">Also, the ending was a serious let down.</span> <span style=\"color:red\">No resolution or big twist or anything.</span> <span style=\"color:red\"><br /><br />But as a low budget horror movie, it's pretty fun to watch.</span> <span style=\"color:grey\">If you're into cheesy spookfests, you should have a laugh watching this one.</span> <span style=\"color:grey\">I think one of it's faults though... that it takes itself too seriously.</span> <span style=\"color:orange\">It's a silly movie, and if it was a little more self-aware when it comes to that, I think it would have been better.</span> <span style=\"color:grey\">But at least there's enough neat carnival themes and b-movie monster makeup to keep you watching.\"</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 8: Visualizing the Results of individual sentence sentiment by color\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def highlight_sentences(review_text, sentences, scores):\n",
    "    highlighted_text = review_text\n",
    "    for sentence, score in zip(sentences, scores):\n",
    "        # Determine color based on score\n",
    "        if score > 0.9:\n",
    "            color = 'chartreuse'  # Very strongly positive\n",
    "        elif score > 0.8:\n",
    "            color = 'limegreen'  # Strongly positive\n",
    "        elif score > 0.7:\n",
    "            color = 'yellowgreen'  # Moderately positive\n",
    "        elif score > 0.6:\n",
    "            color = 'yellowgreen'  # Slightly positive\n",
    "\n",
    "        # Neutral as grey\n",
    "\n",
    "        elif score < 0.1:\n",
    "            color = 'red'  # Very strongly negative\n",
    "        elif score < 0.2:\n",
    "            color = 'orange'  # Strongly negative\n",
    "        elif score < 0.3:\n",
    "            color = 'yellow'  # Moderately negative\n",
    "        elif score < 0.4:\n",
    "            color = 'yellow'  # Slightly negative\n",
    "        else:\n",
    "            color = 'grey'  # Neutral\n",
    "        # Wrap the sentence with a span tag\n",
    "        highlighted_sentence = f'<span style=\"color:{color}\">{sentence}</span>'\n",
    "        # Replace the sentence in the review text\n",
    "        highlighted_text = highlighted_text.replace(sentence, highlighted_sentence)\n",
    "    return highlighted_text\n",
    "\n",
    "\n",
    "# For each review\n",
    "for idx, row in selected_reviews.iterrows():\n",
    "    review_text = row['review']\n",
    "    sentences = row['sentences']\n",
    "    scores = row['sentence_scores']\n",
    "    print(row['sentiment'])\n",
    "    highlighted_review = highlight_sentences(review_text, sentences, scores)\n",
    "    display(HTML(f\"<p>{highlighted_review}</p>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 21222:\n",
      "Overall Sentiment: Positive\n",
      "Sentences sorted by sentiment score:\n",
      "  [1.00] When television was still a young medium, there was a form of entertainment very prominent on the air that is but a memory today: musical variety.\n",
      "  [1.00] Some musical shows were weekly series, but others were single, one-time specials, usually showcasing the special talent of the individual performer.\n",
      "  [0.99] <br /><br />It amazes me that she still had the film debut of FUNNY GIRL yet to come, as well as turns as songwriter, director, and political activist.\n",
      "  [0.99] In 1966, COLOR ME BARBRA introduced Barbra Streisand in color (hence the title), but copied the format of her first special a year earlier almost to the letter.\n",
      "  [0.96] This is where we get the raw, uninhibited first looks at Streisand.\n",
      "  [0.95] Before the Broadway phenomenon of the mid-60's.\n",
      "  [0.95] Check it out.\"\n",
      "  [0.93] It is not until Act 3, believe it or not, that the moment is matched or bettered by another feat: in the concert sequence, in a white gown and pearl earrings, Streisand recites the torchy \\\"Any Place I Hang My Hat is Home,\\\" tearing into the final notes and revealing one of those climactic belts that makes you scream like a little girl even if you're 44 years old...and a guy.\n",
      "  [0.83] To really appreciate the enigma that is Barbra Streisand, you have to look back before the movies.\n",
      "  [0.79] Here, she is barely 24 years old, doing extraordinary things because, as she puts it in her own on-camera introduction, 'we didn't know we couldn't, so we did.'\n",
      "  [0.60] She had already been a guest performer on other variety shows including Garry Moore, Ed Sullivan, and scored a major coup in a one-time only tandem appearance with the woman who would pass her the baton of belter extraordinary: Judy Garland.\n",
      "  [0.59] Yet there are cuts, dissolves, and tracking shots galore, resulting in one rather spectacular peak moment-- the modern, slightly beatnik-flavored, \\Gotta Move.\\\" After getting lost amongst the modern abstracts, jazz-club bongos begin, with Streisand emerging in a psychedelic gown and glittering eye makeup, doing the catchy staccato tune with almost androgynous sex appeal.\n",
      "  [0.52] Well, I fear that my review of this special won't heed much different observation than the others before me, but I literally just watched it- during a PBS membership drive- and frankly I'm too excited NOT to say anything.\n",
      "  [0.31] In 3 distinct acts, we get an abstract Streisand (in an after-hours art museum looking at and sometimes becoming the works of art), a comic Streisand working an already adoring audience in a studio circus (populated with many fuzzy and furry animals), and best of all, a singing Streisand in mini-concert format just-- well, frankly, just doing it.\n",
      "  [0.06] Just plain old great television.\n",
      "  [0.03] The art museum sequence is shot in Philadelphia over one weekend immediately after the museum closed to the public on Saturday evening, and apparently done with only ONE color camera.\n",
      "--------------------------------------------------\n",
      "Review 1797:\n",
      "Overall Sentiment: Positive\n",
      "Sentences sorted by sentiment score:\n",
      "  [1.00] These scenes are here and are fantastic (especially the ending where we see Sasha's full powers unleashed in desperation).\n",
      "  [1.00] This is a tragic love story and a refreshing entry into the genre.\"\n",
      "  [1.00] Don't worry though, the action is there and plenty of it.\n",
      "  [1.00] Unbreakable?\n",
      "  [0.99] He meets a girl and falls in love instantly as does she and this is really what the movie is about.<br /><br />The film is highly impressionistic with bold colors and noir overtones spliced with short yet extreme action sequences.\n",
      "  [0.99] This is where the vengeance and anger comes into play.\n",
      "  [0.98] The directors approach for this genre is refreshing focusing on the emotional journey of Sasha and not a straight action film.\n",
      "  [0.96] When he wishes or his anger allows, a sword extends from his arm piercing his own skin.\n",
      "  [0.96] It's this odd mash that interests me so much in this film.\n",
      "  [0.90] This is not to say that action is not shown.\n",
      "  [0.88] The Watchmen?\n",
      "  [0.86] This is art house at it's core, beautifully filmed with such attention to details in every scene over gruesome sci-fi action.\n",
      "  [0.75] However, the Russian sci-fi action flick, The Sword Bearer, is far from the standard stock.<br /><br />The story revolves around a man named Sasha who as a boy was shunned from society, his peers and family due to a supernatural power that he possess.\n",
      "  [0.60] Shunned all his life and driven by anger (and a temper he does have) our \\hero\\\" returns to his home town to turn his life around or find a reason to.\n",
      "  [0.59] What happens when the average joe finds out he has supernatural powers?\n",
      "  [0.30] This is a man you do not want to cross and from this point the mafia and the police are on his tail.\n",
      "  [0.28] However, much of these sequences show only implied violence with pictures of the horrific aftermath.\n",
      "  [0.18] The director chooses to imply the violence of many scenes to keep the focus on the character's emotional struggle at hand.\n",
      "  [0.18] The premise may sound familiar.\n",
      "  [0.04] The only thing he encounters here is trouble when an encounter with an old flame's new boyfriend leaves him bloodied on the ground.\n",
      "  [0.04] Very wolverinish?\n",
      "  [0.01] Maybe... but that's not the interesting part of this film.\n",
      "--------------------------------------------------\n",
      "Review 3876:\n",
      "Overall Sentiment: Positive\n",
      "Sentences sorted by sentiment score:\n",
      "  [0.93] Its a great light hearted film, the songs aren't memorable probably if i was a child during the time it came out i would have stuck in my mind more.\n",
      "  [0.89] For years i've had a distant memory of watching this film , i looked on the net to find it somewhere and couldn't find it anywhere so i thought it must have disappeared.<br /><br />UNTIL...my gran showed me a box set she sent off for in the Daily Mail and i though nah there wont be anything decent in there, but to my great surprise there amongst other gems was The Water Babies!\n",
      "  [0.58] But who cares when your a kid you never think of those things, even if they lead boy is about 10 and sounds like a boy in the middle of puberty.<br /><br />Great classic kids film!\n",
      "  [0.28] Sadly it was just a film i watched at my grans 10 years ago when i was a little spud.\n",
      "  [0.03] I hadn't been that excited ina long long time!\n",
      "  [0.03] and the re-recored voices they do to get a richness to the sound in films is totally off!\n",
      "  [0.03] And watching it back now the animation is terrible!\n",
      "--------------------------------------------------\n",
      "Review 4277:\n",
      "Overall Sentiment: Positive\n",
      "Sentences sorted by sentiment score:\n",
      "  [0.97] This film is a brilliant retelling of Shakespeare's classic love story, complete with \\kinky sex, body piercing, and dismemberment\\\".\n",
      "  [0.82] It does follow the same spirit as all the other Troma movies [except Combat Shock...That sucker was depressing] but it's not only for Troma fans.\n",
      "  [0.81] This movie should be viewed by all, because it remains faithful to the original story while still being jam-packed with Troma's trademark gore/sex humor.\"\n",
      "  [0.46] The acting is also surprisingly good, and you can just feel Sammy Capulet's pain as he tries to put his brain back into his head.<br /><br />The soundtrack, which contains many original and high-energy bands like The Wesley Willis Fiasco, Supernova, and The Meatmen is also four-star.\n",
      "  [0.28] Anybody who appreciates lowbrow visuals and a hilarious script will without a doubt fall in love with this movie.<br /><br />Don't expect pretentious, artistic-wannabe crap like the version of R&J with Claire Danes and Leo DiCaprio; this one knows its a silly movie and draws its humor from that.\n",
      "--------------------------------------------------\n",
      "Review 12026:\n",
      "Overall Sentiment: Positive\n",
      "Sentences sorted by sentiment score:\n",
      "  [1.00] Mas Oyama was the most successful karate master of the late 20th century.\n",
      "  [1.00] Sonny Chiba portrays his master with conviction and the karate is quite good.\n",
      "  [0.99] He eventually built his system into a huge business empire with hundreds of schools across the world, without compromising his teachings.\n",
      "  [0.99] Possibly it the very realistic depictions of martial arts.\n",
      "  [0.97] He was called on to repeat this feat numerous times.\n",
      "  [0.97] In this series, Oyama's most famous student, Sonny Chiba, is called upon to portray his master.<br /><br />Oyama arrives from the countryside where he has been training alone.\n",
      "  [0.97] This movie series was part of that effort although anyone who had the chance to meet Oyama (I did) would never question his allegiance to Japan.\n",
      "  [0.96] Perhaps viewers rather not have their entertainment reflect reality so closely.<br /><br />Recommended especially for martial artists.\"\n",
      "  [0.96] The testing in the Kyokushin schools are still some of the most physically challenging tests any martial art school requires.\n",
      "  [0.96] I always wondered why it's not more well known.\n",
      "  [0.95] There are filmed instances of Oyama actually doing this, although sometimes the bulls seemed to be tethered as Oyama was getting on in years.\n",
      "  [0.93] People are shown getting tired and hurt unlike 99% of action film where the hero is a limitless fountain of energy and each blow instantly dispatches an opponent to death.\n",
      "  [0.87] In the middle of this is the legendary bullfight with a mad bull.\n",
      "  [0.83] <br /><br />As a whole the movie is good, much better then most martial art films in the drama department.\n",
      "  [0.75] He eventually picks up a student, falls in love and gets in the way of gangsters who are allied with the established karate schools.\n",
      "  [0.73] He challenges and makes short work of the established Karate schools he encounters.\n",
      "  [0.67] Chiba may not have been the best karate practitioner but, at this point in time, he was certainly above average.\n",
      "  [0.32] One non- physical hardship Oyama faced was prejudice due to his Korean ancestry and he spent time proving that loyalties were to Japan and Japanese Karate.\n",
      "  [0.25] How much of the film is true is questionable.<br /><br />That Oyama could kill a bull with his bare hands is true.\n",
      "  [0.10] Chiba seems so exhausted at one point that it hurts to watch.\n",
      "  [0.05] He rejected the \\training\\\" of the karate clubs of the time focusing on an intense no holds form of training.\n",
      "  [0.02] Disgusted by the state of karate, Oyama returns to his lone training.\n",
      "--------------------------------------------------\n",
      "Review 23249:\n",
      "Overall Sentiment: Negative\n",
      "Sentences sorted by sentiment score:\n",
      "  [0.99] Too bad.<br /><br />I can appreciate how the people you kind of hate at the beginning are the ones you kind of like at the end, and vice-versa, so there is some sort of character arc, at least in terms of perception.\n",
      "  [0.99] The scene where the Lord visits Wilkinson and relates how brave Watson is, the bestest nurse any dying boyfriend could ever ask for, Florence Nightingale incarnate, etc.\n",
      "  [0.99] For example, Watson's character, while refreshingly honest to her husband about her feelings for another man, began to grate on me near the end, particularly when she announced to her husband that she simply had absolutely no control over her actions, and later when she simply declared that she would be moving back into their marital flat, with no asking of permission, no apologies offered.\n",
      "  [0.92] I'm not anti PC or anything, it just didn't ring true, even after taking into account all of the harsh realities of middle age we all tend to face.\n",
      "  [0.84] Good God!\n",
      "  [0.81] I'm not above wanting my emotions manipulated by a story, it just has to be somewhat plausible and not hackneyed.\n",
      "  [0.30] I'm a huge fan of both Emily Watson (Breaking The Waves) and Tom Wilkinson (Normal) and was amused to see them upstaged by Rupert Everett (Dellamorte Dellamore) in this shockingly rather minor movie that had all the ingredients to be so much more.\n",
      "  [0.21] The Lord's dog?).\n",
      "  [0.11] Is that asking too much?<br /><br />My score: 4/10\"\n",
      "  [0.10] was OK until he started over-the-top sobbing like a baby.\n",
      "  [0.10] But for a love triangle there was remarkably little chemistry to speak of between anyone.\n",
      "  [0.07] The movie spent the last 80 minutes convincing me that these two people just don't belong together, so I found no joy in the promise of their relationship continuing.\n",
      "  [0.03] If you ask me she's just another flitty rich person with way too much time on her hands, and so she drives her hard working, well providing spouse crazy with unnecessary drama.\n",
      "  [0.02] Clearly the work of a first-time director with a small budget who either lacked or didn't sufficiently heed good advice.\n",
      "  [0.02] Her screwing around was just another way to occupy her empty life; the dying guy thing was an added bonus for her as it somehow made her previous actions completely above reproach.<br /><br />Look, everyone would have been better off if Wilkinson had just left her for his secretary, who seemed to appreciate him for who he was.\n",
      "  [0.02] The ending for me was (and not the director's intention I am certain) depressing.\n",
      "  [0.02] The too brief scenes in which he portrays a languid, infinitely entitled, worthless son of a rich Lord are spot-on and entertaining.\n",
      "  [0.01] The music was annoyingly movie-of-the-week quality, and the voice-over jarring and totally unnecessary.\n",
      "  [0.00] Instead he acted like an abused dog, his open craving for his wife's affection increasing with every kick she gives him.\n",
      "  [0.00] And I went from disliking Wilkinson's control freak / moral relativist character to sort of understanding him and not really wanting him to change (unlike his wife).<br /><br />This movie awkwardly morphed from a whodunit to a \\Love Story\\\" or \\\"Steel Magnolias\\\" illness drama without sufficiently informing me of the fact, so I was left distractedly guessing what the next plot twist might be long after they had all been revealed (Was it the Lord driving the car?\n",
      "--------------------------------------------------\n",
      "Review 15018:\n",
      "Overall Sentiment: Negative\n",
      "Sentences sorted by sentiment score:\n",
      "  [0.99] Watch this one if you're a fan of the genre and you've already seen the bestbut don't expect too much.\n",
      "  [0.90] ), but there are much better giallo's out there.\n",
      "  [0.78] Alan (Anthony Steffen), an English multi-millionaire with a few screws loose (thanks to his first wife's infidelity and untimely death during childbirth), entices sexy, red-headed women to his castle, offering them bundles of cash to stay the weekend.\n",
      "  [0.22] Once back at his ancestral pile, he gets them nekkid, proceeds to flog them with a bull-whip, and then kills them.<br /><br />But when he meets blonde hottie Gladys (Marina Malfatti) and falls for her ample charms, he decides to give up his murderous ways and get married.\n",
      "  [0.18] Their wedded bliss is short-lived, however, thanks to Alan's iffy mental state, which becomes increasingly fragile when his dead wife Evelyn starts to appear outside his window and a spate of gruesome murders occur within the castle grounds.<br /><br />So let's recap: a groovy 70s Euro-horror with loads of tasty women in various states of undress; spooky Gothic retreats and misty graveyards; a sadistic rich psycho with a penchant for drop-dead gorgeous babes with cracking bods; several vicious murders (including a great bit where one victim has her head bashed in with a rock and her entrails eaten by foxes).\n",
      "  [0.05] Secondly, Emilio Maraglia's direction is pretty torpid.\n",
      "  [0.01] Well, for starters, the plot is way too convoluted: there are red herrings, crazy plot developments, and suspects galore, and it all becomes a bit too much.\n",
      "  [0.01] Stylish, yes; but as slow as molasses at times.<br /><br />And then there's the bits that are just too damn silly, possibly even for a giallo: the death by poisonous snake bite (surely one of the most bizarre choices of weapon ever); Alan's Aunt Agatha, an old crippled relative who is played by a pretty young woman; the hiring of a group of identical curly headed blondes as maids; the poor attempt at convincing the audience that the film is set in England (mentioning 'pounds' and hiring a crap police uniform for one of the extras is not enough); and then, of course, there is the unlikelihood of finding a bag of sulphuric acid laying next to a swimming pool...<br /><br />'The Night Evelyn Came Out Of Her Grave' isn't a total waste of time (how could it be, with so much female flesh on show?\n",
      "  [0.00] By the ridiculous endingin which we discover that, all along, several people have been plotting to get their greedy paws on Alan's wealth, and that our red-head killing nut-job is actually supposed to be the hero of the moviemy head was hurting too much to care!\n",
      "  [0.00] Normally, a checklist like that would guarantee me a good timeso why did I find 'The Night Evelyn Came Out Of Her Grave' so dull?\n",
      "--------------------------------------------------\n",
      "Review 23733:\n",
      "Overall Sentiment: Negative\n",
      "Sentences sorted by sentiment score:\n",
      "  [0.99] It suits them well.\n",
      "  [0.97] Family goes away on vacation and 16 year old daughter wants independence from parents.\n",
      "  [0.97] It's called proofreading and editing.\n",
      "  [0.87] The Wizards of Waverly Place Movie??\n",
      "  [0.86] Do it sometime, Disney.\n",
      "  [0.83] <br /><br />Has anyone seen the promo for the new \\\"four part bloodsucking saga\\\"?\n",
      "  [0.82] Wanna know why?\n",
      "  [0.81] <br /><br />Hello?\n",
      "  [0.53] Think about it for a minute.\n",
      "  [0.53] Disney wanted their own version of the Twilight vs. Harry Potter thing.\n",
      "  [0.42] In one episode, the security guard is called \\\"sir\\\" by one character and referred to as a woman by all else.\n",
      "  [0.39] Jake T. Austin's character needs some Ritalin.\n",
      "  [0.38] Except a million times lamer.\n",
      "  [0.31] how many more years?\n",
      "  [0.17] And most of the audience are some-what age's 4-13 (And no life teenagers).\n",
      "  [0.04] David Henrie's character needs to visit a strip club and get wasted.\n",
      "  [0.02] This is what Disney Channel shows to kids who are dumber than posts.\n",
      "  [0.01] It's not funny, the acting is the worst I've seen in many years, there are more stereotypes than there are actors, and everything about this show makes you groan and roll your eyes.\n",
      "  [0.00] SAME PLOT from The Proud Family Movie etc...<br /><br />What's worse is all the Emmies and ALMA'S it got.\n",
      "  [0.00] before selena gomez is showing her tits?<br /><br />and Disney shows are all crap..hack writers..hack shows..destroying the minds and wallets of today's youth..\"\n",
      "  [0.00] Also, the writer of the show is inconsistent.\n",
      "  [0.00] Not only is this show a waste of airtime, the lead \\actress\\\" Selena Gomez looks like a pig.\n",
      "--------------------------------------------------\n",
      "Review 15808:\n",
      "Overall Sentiment: Negative\n",
      "Sentences sorted by sentiment score:\n",
      "  [1.00] Everything is so very peachy and swell--the family adores Bergman and things couldn't be more perfect.\n",
      "  [0.99] This portion of the film is a bit sticky sweet, but not bad.<br /><br />Later, after the family's fortunes have improved, Bergman returns.\n",
      "  [0.99] In the midst of this, one of the sons (David) brings home his new wife (Susan Hayward).\n",
      "  [0.97] Hayward begins an affair with one of David's brothers but when the father sees a silhouette of the lovers, Bergman enters the room from another entrance and pretends that it was her, not Hayward with Jack!\n",
      "  [0.95] Miss Hayward's character is as black and white as the others, though while they are all good and swell, she's obviously a horny she-devil.\n",
      "  [0.93] But, briefly, everything is swell once again.\n",
      "  [0.84] Sadly, the film suffers from difficult to believe characters as well as a major plot problem that makes some of the characters seem brain-addled.<br /><br />The film begins with Ingrid Bergman coming to work for the Stoddard family.\n",
      "  [0.68] But, when WWI occurs, the four all go to war--gosh!\n",
      "  [0.60] Well, that is until the mother (Fay Wray) dies, the stock market crashes in 1907 (wiping out the family's fortune) and Bergman is forced to go back home to France.\n",
      "  [0.47] You'd think that with Ingrid Bergman and Warner Baxter that this film would have been a lot better.\n",
      "  [0.21] Hayward's affair made no sense--at least in how it was handled.\n",
      "  [0.09] This was exactly the sort of excuse Bergman needed to get rid of the gutter-snipe once and for all!\n",
      "  [0.06] The four boys are now all grown and there isn't really a conceivable reason why they'd hire her once again as a governess.\n",
      "  [0.03] And, having characters who are so gosh-darn good or evil (with nothing in between) sinks this movie to the level of a second-rate soap.\n",
      "  [0.03] WHY?!\n",
      "  [0.02] This is just a case of lousy writing and made me mad...and most likely did the same to the audiences back in 1941.<br /><br />The rest of the movie consists of failed opportunity after failed opportunity for Hayward's evilness to be exposed.\n",
      "  [0.01] Suffice to say that the Columbia Pictures writers who did this film should have been slapped with a dead chicken!\n",
      "  [0.00] To make things worse, she comes to live in the family home while David is at war.<br /><br />Now here is where the movie gets really, really dumb--brain-achingly dumb.\n",
      "  [0.00] The only thing that saves it at all is the acting---they tried as best they could with a turgid script.\n",
      "  [0.00] Why would any sane person do this to save the butt of an obviously evil and conniving woman?\n",
      "  [0.00] As expected, however, the truth eventually comes out and everyone is swell once again---happy to be one big loving wonderful family minus the slut, Hayward.<br /><br />The film suffers because of poor writing.\n",
      "  [0.00] This just flies against common sense and made the film a silly melodramatic mess.\n",
      "--------------------------------------------------\n",
      "Review 19238:\n",
      "Overall Sentiment: Negative\n",
      "Sentences sorted by sentiment score:\n",
      "  [0.99] He decides to teach the teens a lesson by making them part of the freak show.\n",
      "  [0.83] Someone else called this film a \\fable-horror\\\" movie, and I think that fits pretty well.\n",
      "  [0.74] That's the concept at least.\n",
      "  [0.49] But at least there's enough neat carnival themes and b-movie monster makeup to keep you watching.\"\n",
      "  [0.43] If you're into cheesy spookfests, you should have a laugh watching this one.\n",
      "  [0.41] I think one of it's faults though... that it takes itself too seriously.\n",
      "  [0.40] A cool idea, but could have been executed better.\n",
      "  [0.36] The fate for some of the teens is shoved in your face too obviously, while other characters could have been fleshed out more.\n",
      "  [0.23] A group of teenagers, each with their own vice, catch the eye of a twisted sideshow barker.\n",
      "  [0.12] Also, the ending was a serious let down.\n",
      "  [0.12] It's a silly movie, and if it was a little more self-aware when it comes to that, I think it would have been better.\n",
      "  [0.10] <br /><br />But as a low budget horror movie, it's pretty fun to watch.\n",
      "  [0.03] No resolution or big twist or anything.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print review details with sentences sorted by sentiment scores\n",
    "for idx, row in selected_reviews.iterrows():\n",
    "    print(f\"Review {idx + 1}:\")\n",
    "    sentiment = \"Positive\" if row['sentiment'] == 1 else \"Negative\"\n",
    "    print(f\"Overall Sentiment: {sentiment}\")\n",
    "\n",
    "    # Pair sentences with their scores\n",
    "    sentences = row['sentences']\n",
    "    scores = row['sentence_scores']\n",
    "    sentence_analysis = list(zip(sentences, scores))\n",
    "\n",
    "    # Sort sentences by score\n",
    "    sorted_sentences = sorted(sentence_analysis, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Sentences sorted by sentiment score:\")\n",
    "    for sentence, score in sorted_sentences:\n",
    "        print(f\"  [{score:.2f}] {sentence}\")\n",
    "\n",
    "    print(\"-\" * 50)  # Separator for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Prepare for Leave-one-out: Sentiment Analysis for Full Embedded Reviews\n",
    "\n",
    "# Add a new column for full review sentiment scores\n",
    "selected_reviews['full_review_score'] = None\n",
    "\n",
    "for idx, row in selected_reviews.iterrows():\n",
    "    # Preprocess the full review\n",
    "    full_review_text = preprocess_text(row['review'])\n",
    "\n",
    "    # Embed the full review with BERT\n",
    "    full_review_embedding = get_review_embedding(full_review_text, tokenizer, bert_model, device)\n",
    "    full_review_embedding = full_review_embedding.reshape(1, -1)  # Reshape for scaler compatibility\n",
    "\n",
    "    bert_emb_reshaped = full_review_embedding.reshape(1, -1)\n",
    "\n",
    "    # Transform BERT -> OpenAI using the learned mapping\n",
    "    scaled_bert_emb = bert_scaler.transform(bert_emb_reshaped)\n",
    "    open_ai_review_emb = lin_reg.predict(scaled_bert_emb)\n",
    "\n",
    "    # Scale the input embedding\n",
    "    open_ai_emb_scaled = logreg_sentiment_scaler.transform(open_ai_review_emb.reshape(1, -1))\n",
    "    # Predict sentiment using the logistic regression classifier\n",
    "    full_review_score = logreg_sentiment_model.predict_proba(open_ai_emb_scaled)[0, 1]\n",
    "\n",
    "    # Store the score in the DataFrame\n",
    "    selected_reviews.at[idx, 'full_review_score'] = full_review_score\n",
    "\n",
    "# Display the full review sentiment scores\n",
    "# print(selected_reviews[['review', 'sentiment', 'full_review_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Leave-One-Out Analysis for Sentences\n",
    "\n",
    "# Add a new column to store leave-one-out differences for each sentence\n",
    "selected_reviews['leave_one_out_differences'] = None\n",
    "\n",
    "for idx, row in selected_reviews.iterrows():\n",
    "    leave_one_out_differences = []\n",
    "    base_score = row['full_review_score']  # Base sentiment score for the full review\n",
    "\n",
    "    # For each sentence in the review\n",
    "    for i, sentence in enumerate(row['sentences']):\n",
    "        # Create the modified review by omitting the current sentence\n",
    "        modified_review_text = \" \".join([s for j, s in enumerate(row['sentences']) if j != i])\n",
    "\n",
    "        # Preprocess the modified review\n",
    "        clean_modified_review = preprocess_text(modified_review_text)\n",
    "\n",
    "        # Embed the modified review with BERT\n",
    "        modified_review_embedding = get_review_embedding(clean_modified_review, tokenizer, bert_model, device)\n",
    "        modified_review_embedding = modified_review_embedding.reshape(1, -1)\n",
    "\n",
    "        # Transform BERT -> OpenAI using the learned mapping\n",
    "        scaled_modified_emb = bert_scaler.transform(modified_review_embedding)\n",
    "        openai_modified_emb = lin_reg.predict(scaled_modified_emb)\n",
    "\n",
    "        # Scale the transformed embedding\n",
    "        openai_emb_scaled = logreg_sentiment_scaler.transform(openai_modified_emb.reshape(1, -1))\n",
    "\n",
    "        # Predict sentiment for the modified review\n",
    "        modified_score = logreg_sentiment_model.predict_proba(openai_emb_scaled)[0, 1]\n",
    "\n",
    "        # Calculate the difference from the base score\n",
    "        score_difference = base_score - modified_score\n",
    "        leave_one_out_differences.append(score_difference)\n",
    "\n",
    "    # Store the differences in the DataFrame\n",
    "    selected_reviews.at[idx, 'leave_one_out_differences'] = leave_one_out_differences\n",
    "\n",
    "# Display the leave-one-out differences\n",
    "# print(selected_reviews[['review', 'sentiment', 'leave_one_out_differences']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 21222:\n",
      "Overall Sentiment: Positive\n",
      "Base Sentiment Score: 0.99\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.0487] Yet there are cuts, dissolves, and tracking shots galore, resulting in one rather spectacular peak moment-- the modern, slightly beatnik-flavored, \\Gotta Move.\\\" After getting lost amongst the modern abstracts, jazz-club bongos begin, with Streisand emerging in a psychedelic gown and glittering eye makeup, doing the catchy staccato tune with almost androgynous sex appeal.\n",
      "  [Impact: 0.0271] In 3 distinct acts, we get an abstract Streisand (in an after-hours art museum looking at and sometimes becoming the works of art), a comic Streisand working an already adoring audience in a studio circus (populated with many fuzzy and furry animals), and best of all, a singing Streisand in mini-concert format just-- well, frankly, just doing it.\n",
      "  [Impact: 0.0202] Some musical shows were weekly series, but others were single, one-time specials, usually showcasing the special talent of the individual performer.\n",
      "  [Impact: 0.0137] Check it out.\"\n",
      "  [Impact: 0.0126] It is not until Act 3, believe it or not, that the moment is matched or bettered by another feat: in the concert sequence, in a white gown and pearl earrings, Streisand recites the torchy \\\"Any Place I Hang My Hat is Home,\\\" tearing into the final notes and revealing one of those climactic belts that makes you scream like a little girl even if you're 44 years old...and a guy.\n",
      "  [Impact: 0.0107] The art museum sequence is shot in Philadelphia over one weekend immediately after the museum closed to the public on Saturday evening, and apparently done with only ONE color camera.\n",
      "  [Impact: 0.0094] <br /><br />It amazes me that she still had the film debut of FUNNY GIRL yet to come, as well as turns as songwriter, director, and political activist.\n",
      "  [Impact: 0.0093] To really appreciate the enigma that is Barbra Streisand, you have to look back before the movies.\n",
      "  [Impact: 0.0091] When television was still a young medium, there was a form of entertainment very prominent on the air that is but a memory today: musical variety.\n",
      "  [Impact: 0.0041] This is where we get the raw, uninhibited first looks at Streisand.\n",
      "  [Impact: 0.0036] Before the Broadway phenomenon of the mid-60's.\n",
      "  [Impact: 0.0031] Well, I fear that my review of this special won't heed much different observation than the others before me, but I literally just watched it- during a PBS membership drive- and frankly I'm too excited NOT to say anything.\n",
      "  [Impact: 0.0014] She had already been a guest performer on other variety shows including Garry Moore, Ed Sullivan, and scored a major coup in a one-time only tandem appearance with the woman who would pass her the baton of belter extraordinary: Judy Garland.\n",
      "  [Impact: -0.0005] Just plain old great television.\n",
      "  [Impact: -0.0017] Here, she is barely 24 years old, doing extraordinary things because, as she puts it in her own on-camera introduction, 'we didn't know we couldn't, so we did.'\n",
      "  [Impact: -0.0025] In 1966, COLOR ME BARBRA introduced Barbra Streisand in color (hence the title), but copied the format of her first special a year earlier almost to the letter.\n",
      "--------------------------------------------------\n",
      "Review 1797:\n",
      "Overall Sentiment: Positive\n",
      "Base Sentiment Score: 0.98\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.0237] Unbreakable?\n",
      "  [Impact: 0.0141] The Watchmen?\n",
      "  [Impact: 0.0112] This is where the vengeance and anger comes into play.\n",
      "  [Impact: 0.0102] Very wolverinish?\n",
      "  [Impact: 0.0046] It's this odd mash that interests me so much in this film.\n",
      "  [Impact: 0.0042] The premise may sound familiar.\n",
      "  [Impact: 0.0023] Don't worry though, the action is there and plenty of it.\n",
      "  [Impact: 0.0020] This is not to say that action is not shown.\n",
      "  [Impact: -0.0041] He meets a girl and falls in love instantly as does she and this is really what the movie is about.<br /><br />The film is highly impressionistic with bold colors and noir overtones spliced with short yet extreme action sequences.\n",
      "  [Impact: -0.0063] However, the Russian sci-fi action flick, The Sword Bearer, is far from the standard stock.<br /><br />The story revolves around a man named Sasha who as a boy was shunned from society, his peers and family due to a supernatural power that he possess.\n",
      "  [Impact: -0.0074] However, much of these sequences show only implied violence with pictures of the horrific aftermath.\n",
      "  [Impact: -0.0076] The director chooses to imply the violence of many scenes to keep the focus on the character's emotional struggle at hand.\n",
      "  [Impact: -0.0083] This is a man you do not want to cross and from this point the mafia and the police are on his tail.\n",
      "  [Impact: -0.0083] This is a tragic love story and a refreshing entry into the genre.\"\n",
      "  [Impact: -0.0105] These scenes are here and are fantastic (especially the ending where we see Sasha's full powers unleashed in desperation).\n",
      "  [Impact: -0.0107] This is art house at it's core, beautifully filmed with such attention to details in every scene over gruesome sci-fi action.\n",
      "  [Impact: -0.0131] What happens when the average joe finds out he has supernatural powers?\n",
      "  [Impact: -0.0139] The directors approach for this genre is refreshing focusing on the emotional journey of Sasha and not a straight action film.\n",
      "  [Impact: -0.0139] Maybe... but that's not the interesting part of this film.\n",
      "  [Impact: -0.0144] Shunned all his life and driven by anger (and a temper he does have) our \\hero\\\" returns to his home town to turn his life around or find a reason to.\n",
      "  [Impact: -0.0157] When he wishes or his anger allows, a sword extends from his arm piercing his own skin.\n",
      "  [Impact: -0.0158] The only thing he encounters here is trouble when an encounter with an old flame's new boyfriend leaves him bloodied on the ground.\n",
      "--------------------------------------------------\n",
      "Review 3876:\n",
      "Overall Sentiment: Positive\n",
      "Base Sentiment Score: 0.69\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.5848] But who cares when your a kid you never think of those things, even if they lead boy is about 10 and sounds like a boy in the middle of puberty.<br /><br />Great classic kids film!\n",
      "  [Impact: 0.1262] Its a great light hearted film, the songs aren't memorable probably if i was a child during the time it came out i would have stuck in my mind more.\n",
      "  [Impact: -0.0198] Sadly it was just a film i watched at my grans 10 years ago when i was a little spud.\n",
      "  [Impact: -0.0694] I hadn't been that excited ina long long time!\n",
      "  [Impact: -0.1038] For years i've had a distant memory of watching this film , i looked on the net to find it somewhere and couldn't find it anywhere so i thought it must have disappeared.<br /><br />UNTIL...my gran showed me a box set she sent off for in the Daily Mail and i though nah there wont be anything decent in there, but to my great surprise there amongst other gems was The Water Babies!\n",
      "  [Impact: -0.1072] and the re-recored voices they do to get a richness to the sound in films is totally off!\n",
      "  [Impact: -0.1788] And watching it back now the animation is terrible!\n",
      "--------------------------------------------------\n",
      "Review 4277:\n",
      "Overall Sentiment: Positive\n",
      "Base Sentiment Score: 0.99\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.1326] The acting is also surprisingly good, and you can just feel Sammy Capulet's pain as he tries to put his brain back into his head.<br /><br />The soundtrack, which contains many original and high-energy bands like The Wesley Willis Fiasco, Supernova, and The Meatmen is also four-star.\n",
      "  [Impact: 0.1141] This movie should be viewed by all, because it remains faithful to the original story while still being jam-packed with Troma's trademark gore/sex humor.\"\n",
      "  [Impact: 0.0235] This film is a brilliant retelling of Shakespeare's classic love story, complete with \\kinky sex, body piercing, and dismemberment\\\".\n",
      "  [Impact: -0.0017] It does follow the same spirit as all the other Troma movies [except Combat Shock...That sucker was depressing] but it's not only for Troma fans.\n",
      "  [Impact: -0.0047] Anybody who appreciates lowbrow visuals and a hilarious script will without a doubt fall in love with this movie.<br /><br />Don't expect pretentious, artistic-wannabe crap like the version of R&J with Claire Danes and Leo DiCaprio; this one knows its a silly movie and draws its humor from that.\n",
      "--------------------------------------------------\n",
      "Review 12026:\n",
      "Overall Sentiment: Positive\n",
      "Base Sentiment Score: 0.97\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.0697] In this series, Oyama's most famous student, Sonny Chiba, is called upon to portray his master.<br /><br />Oyama arrives from the countryside where he has been training alone.\n",
      "  [Impact: 0.0456] Sonny Chiba portrays his master with conviction and the karate is quite good.\n",
      "  [Impact: 0.0253] Perhaps viewers rather not have their entertainment reflect reality so closely.<br /><br />Recommended especially for martial artists.\"\n",
      "  [Impact: 0.0127] This movie series was part of that effort although anyone who had the chance to meet Oyama (I did) would never question his allegiance to Japan.\n",
      "  [Impact: 0.0099] He challenges and makes short work of the established Karate schools he encounters.\n",
      "  [Impact: 0.0093] Disgusted by the state of karate, Oyama returns to his lone training.\n",
      "  [Impact: 0.0083] He eventually picks up a student, falls in love and gets in the way of gangsters who are allied with the established karate schools.\n",
      "  [Impact: 0.0068] In the middle of this is the legendary bullfight with a mad bull.\n",
      "  [Impact: 0.0067] Mas Oyama was the most successful karate master of the late 20th century.\n",
      "  [Impact: 0.0063] He was called on to repeat this feat numerous times.\n",
      "  [Impact: 0.0040] There are filmed instances of Oyama actually doing this, although sometimes the bulls seemed to be tethered as Oyama was getting on in years.\n",
      "  [Impact: -0.0012] How much of the film is true is questionable.<br /><br />That Oyama could kill a bull with his bare hands is true.\n",
      "  [Impact: -0.0038] Chiba may not have been the best karate practitioner but, at this point in time, he was certainly above average.\n",
      "  [Impact: -0.0076] Possibly it the very realistic depictions of martial arts.\n",
      "  [Impact: -0.0086] I always wondered why it's not more well known.\n",
      "  [Impact: -0.0087] <br /><br />As a whole the movie is good, much better then most martial art films in the drama department.\n",
      "  [Impact: -0.0095] One non- physical hardship Oyama faced was prejudice due to his Korean ancestry and he spent time proving that loyalties were to Japan and Japanese Karate.\n",
      "  [Impact: -0.0105] People are shown getting tired and hurt unlike 99% of action film where the hero is a limitless fountain of energy and each blow instantly dispatches an opponent to death.\n",
      "  [Impact: -0.0135] He eventually built his system into a huge business empire with hundreds of schools across the world, without compromising his teachings.\n",
      "  [Impact: -0.0149] He rejected the \\training\\\" of the karate clubs of the time focusing on an intense no holds form of training.\n",
      "  [Impact: -0.0166] The testing in the Kyokushin schools are still some of the most physically challenging tests any martial art school requires.\n",
      "  [Impact: -0.0215] Chiba seems so exhausted at one point that it hurts to watch.\n",
      "--------------------------------------------------\n",
      "Review 23249:\n",
      "Overall Sentiment: Negative\n",
      "Base Sentiment Score: 0.02\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.0120] I'm not anti PC or anything, it just didn't ring true, even after taking into account all of the harsh realities of middle age we all tend to face.\n",
      "  [Impact: 0.0072] Too bad.<br /><br />I can appreciate how the people you kind of hate at the beginning are the ones you kind of like at the end, and vice-versa, so there is some sort of character arc, at least in terms of perception.\n",
      "  [Impact: 0.0027] I'm not above wanting my emotions manipulated by a story, it just has to be somewhat plausible and not hackneyed.\n",
      "  [Impact: -0.0007] Her screwing around was just another way to occupy her empty life; the dying guy thing was an added bonus for her as it somehow made her previous actions completely above reproach.<br /><br />Look, everyone would have been better off if Wilkinson had just left her for his secretary, who seemed to appreciate him for who he was.\n",
      "  [Impact: -0.0060] The movie spent the last 80 minutes convincing me that these two people just don't belong together, so I found no joy in the promise of their relationship continuing.\n",
      "  [Impact: -0.0071] If you ask me she's just another flitty rich person with way too much time on her hands, and so she drives her hard working, well providing spouse crazy with unnecessary drama.\n",
      "  [Impact: -0.0122] Instead he acted like an abused dog, his open craving for his wife's affection increasing with every kick she gives him.\n",
      "  [Impact: -0.0151] For example, Watson's character, while refreshingly honest to her husband about her feelings for another man, began to grate on me near the end, particularly when she announced to her husband that she simply had absolutely no control over her actions, and later when she simply declared that she would be moving back into their marital flat, with no asking of permission, no apologies offered.\n",
      "  [Impact: -0.0170] Good God!\n",
      "  [Impact: -0.0220] The ending for me was (and not the director's intention I am certain) depressing.\n",
      "  [Impact: -0.0276] was OK until he started over-the-top sobbing like a baby.\n",
      "  [Impact: -0.0290] Is that asking too much?<br /><br />My score: 4/10\"\n",
      "  [Impact: -0.0312] The scene where the Lord visits Wilkinson and relates how brave Watson is, the bestest nurse any dying boyfriend could ever ask for, Florence Nightingale incarnate, etc.\n",
      "  [Impact: -0.0383] The music was annoyingly movie-of-the-week quality, and the voice-over jarring and totally unnecessary.\n",
      "  [Impact: -0.0383] Clearly the work of a first-time director with a small budget who either lacked or didn't sufficiently heed good advice.\n",
      "  [Impact: -0.0444] But for a love triangle there was remarkably little chemistry to speak of between anyone.\n",
      "  [Impact: -0.0476] And I went from disliking Wilkinson's control freak / moral relativist character to sort of understanding him and not really wanting him to change (unlike his wife).<br /><br />This movie awkwardly morphed from a whodunit to a \\Love Story\\\" or \\\"Steel Magnolias\\\" illness drama without sufficiently informing me of the fact, so I was left distractedly guessing what the next plot twist might be long after they had all been revealed (Was it the Lord driving the car?\n",
      "  [Impact: -0.0489] The too brief scenes in which he portrays a languid, infinitely entitled, worthless son of a rich Lord are spot-on and entertaining.\n",
      "  [Impact: -0.0860] The Lord's dog?).\n",
      "  [Impact: -0.0965] I'm a huge fan of both Emily Watson (Breaking The Waves) and Tom Wilkinson (Normal) and was amused to see them upstaged by Rupert Everett (Dellamorte Dellamore) in this shockingly rather minor movie that had all the ingredients to be so much more.\n",
      "--------------------------------------------------\n",
      "Review 15018:\n",
      "Overall Sentiment: Negative\n",
      "Base Sentiment Score: 0.05\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.0408] Watch this one if you're a fan of the genre and you've already seen the bestbut don't expect too much.\n",
      "  [Impact: 0.0372] ), but there are much better giallo's out there.\n",
      "  [Impact: 0.0350] Stylish, yes; but as slow as molasses at times.<br /><br />And then there's the bits that are just too damn silly, possibly even for a giallo: the death by poisonous snake bite (surely one of the most bizarre choices of weapon ever); Alan's Aunt Agatha, an old crippled relative who is played by a pretty young woman; the hiring of a group of identical curly headed blondes as maids; the poor attempt at convincing the audience that the film is set in England (mentioning 'pounds' and hiring a crap police uniform for one of the extras is not enough); and then, of course, there is the unlikelihood of finding a bag of sulphuric acid laying next to a swimming pool...<br /><br />'The Night Evelyn Came Out Of Her Grave' isn't a total waste of time (how could it be, with so much female flesh on show?\n",
      "  [Impact: 0.0260] Their wedded bliss is short-lived, however, thanks to Alan's iffy mental state, which becomes increasingly fragile when his dead wife Evelyn starts to appear outside his window and a spate of gruesome murders occur within the castle grounds.<br /><br />So let's recap: a groovy 70s Euro-horror with loads of tasty women in various states of undress; spooky Gothic retreats and misty graveyards; a sadistic rich psycho with a penchant for drop-dead gorgeous babes with cracking bods; several vicious murders (including a great bit where one victim has her head bashed in with a rock and her entrails eaten by foxes).\n",
      "  [Impact: 0.0122] Secondly, Emilio Maraglia's direction is pretty torpid.\n",
      "  [Impact: -0.0189] Normally, a checklist like that would guarantee me a good timeso why did I find 'The Night Evelyn Came Out Of Her Grave' so dull?\n",
      "  [Impact: -0.0582] Well, for starters, the plot is way too convoluted: there are red herrings, crazy plot developments, and suspects galore, and it all becomes a bit too much.\n",
      "  [Impact: -0.0673] Once back at his ancestral pile, he gets them nekkid, proceeds to flog them with a bull-whip, and then kills them.<br /><br />But when he meets blonde hottie Gladys (Marina Malfatti) and falls for her ample charms, he decides to give up his murderous ways and get married.\n",
      "  [Impact: -0.0939] By the ridiculous endingin which we discover that, all along, several people have been plotting to get their greedy paws on Alan's wealth, and that our red-head killing nut-job is actually supposed to be the hero of the moviemy head was hurting too much to care!\n",
      "  [Impact: -0.1232] Alan (Anthony Steffen), an English multi-millionaire with a few screws loose (thanks to his first wife's infidelity and untimely death during childbirth), entices sexy, red-headed women to his castle, offering them bundles of cash to stay the weekend.\n",
      "--------------------------------------------------\n",
      "Review 23733:\n",
      "Overall Sentiment: Negative\n",
      "Base Sentiment Score: 0.01\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.0067] before selena gomez is showing her tits?<br /><br />and Disney shows are all crap..hack writers..hack shows..destroying the minds and wallets of today's youth..\"\n",
      "  [Impact: 0.0039] SAME PLOT from The Proud Family Movie etc...<br /><br />What's worse is all the Emmies and ALMA'S it got.\n",
      "  [Impact: 0.0029] And most of the audience are some-what age's 4-13 (And no life teenagers).\n",
      "  [Impact: 0.0028] In one episode, the security guard is called \\\"sir\\\" by one character and referred to as a woman by all else.\n",
      "  [Impact: 0.0027] Jake T. Austin's character needs some Ritalin.\n",
      "  [Impact: 0.0020] Do it sometime, Disney.\n",
      "  [Impact: 0.0005] Think about it for a minute.\n",
      "  [Impact: -0.0000] <br /><br />Has anyone seen the promo for the new \\\"four part bloodsucking saga\\\"?\n",
      "  [Impact: -0.0003] Family goes away on vacation and 16 year old daughter wants independence from parents.\n",
      "  [Impact: -0.0006] Wanna know why?\n",
      "  [Impact: -0.0008] This is what Disney Channel shows to kids who are dumber than posts.\n",
      "  [Impact: -0.0010] Except a million times lamer.\n",
      "  [Impact: -0.0010] Not only is this show a waste of airtime, the lead \\actress\\\" Selena Gomez looks like a pig.\n",
      "  [Impact: -0.0015] David Henrie's character needs to visit a strip club and get wasted.\n",
      "  [Impact: -0.0020] <br /><br />Hello?\n",
      "  [Impact: -0.0021] The Wizards of Waverly Place Movie??\n",
      "  [Impact: -0.0023] It's called proofreading and editing.\n",
      "  [Impact: -0.0025] It suits them well.\n",
      "  [Impact: -0.0026] Disney wanted their own version of the Twilight vs. Harry Potter thing.\n",
      "  [Impact: -0.0028] how many more years?\n",
      "  [Impact: -0.0038] It's not funny, the acting is the worst I've seen in many years, there are more stereotypes than there are actors, and everything about this show makes you groan and roll your eyes.\n",
      "  [Impact: -0.0046] Also, the writer of the show is inconsistent.\n",
      "--------------------------------------------------\n",
      "Review 15808:\n",
      "Overall Sentiment: Negative\n",
      "Base Sentiment Score: 0.03\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.0255] Everything is so very peachy and swell--the family adores Bergman and things couldn't be more perfect.\n",
      "  [Impact: 0.0250] Miss Hayward's character is as black and white as the others, though while they are all good and swell, she's obviously a horny she-devil.\n",
      "  [Impact: 0.0246] The four boys are now all grown and there isn't really a conceivable reason why they'd hire her once again as a governess.\n",
      "  [Impact: 0.0240] As expected, however, the truth eventually comes out and everyone is swell once again---happy to be one big loving wonderful family minus the slut, Hayward.<br /><br />The film suffers because of poor writing.\n",
      "  [Impact: 0.0237] This portion of the film is a bit sticky sweet, but not bad.<br /><br />Later, after the family's fortunes have improved, Bergman returns.\n",
      "  [Impact: 0.0235] Well, that is until the mother (Fay Wray) dies, the stock market crashes in 1907 (wiping out the family's fortune) and Bergman is forced to go back home to France.\n",
      "  [Impact: 0.0234] In the midst of this, one of the sons (David) brings home his new wife (Susan Hayward).\n",
      "  [Impact: 0.0231] WHY?!\n",
      "  [Impact: 0.0230] Suffice to say that the Columbia Pictures writers who did this film should have been slapped with a dead chicken!\n",
      "  [Impact: 0.0228] Hayward begins an affair with one of David's brothers but when the father sees a silhouette of the lovers, Bergman enters the room from another entrance and pretends that it was her, not Hayward with Jack!\n",
      "  [Impact: 0.0224] Sadly, the film suffers from difficult to believe characters as well as a major plot problem that makes some of the characters seem brain-addled.<br /><br />The film begins with Ingrid Bergman coming to work for the Stoddard family.\n",
      "  [Impact: 0.0217] To make things worse, she comes to live in the family home while David is at war.<br /><br />Now here is where the movie gets really, really dumb--brain-achingly dumb.\n",
      "  [Impact: 0.0216] But, when WWI occurs, the four all go to war--gosh!\n",
      "  [Impact: 0.0213] But, briefly, everything is swell once again.\n",
      "  [Impact: 0.0207] You'd think that with Ingrid Bergman and Warner Baxter that this film would have been a lot better.\n",
      "  [Impact: 0.0171] Hayward's affair made no sense--at least in how it was handled.\n",
      "  [Impact: 0.0164] This was exactly the sort of excuse Bergman needed to get rid of the gutter-snipe once and for all!\n",
      "  [Impact: 0.0146] This just flies against common sense and made the film a silly melodramatic mess.\n",
      "  [Impact: 0.0026] Why would any sane person do this to save the butt of an obviously evil and conniving woman?\n",
      "  [Impact: 0.0000] The only thing that saves it at all is the acting---they tried as best they could with a turgid script.\n",
      "  [Impact: -0.0084] And, having characters who are so gosh-darn good or evil (with nothing in between) sinks this movie to the level of a second-rate soap.\n",
      "  [Impact: -0.0200] This is just a case of lousy writing and made me mad...and most likely did the same to the audiences back in 1941.<br /><br />The rest of the movie consists of failed opportunity after failed opportunity for Hayward's evilness to be exposed.\n",
      "--------------------------------------------------\n",
      "Review 19238:\n",
      "Overall Sentiment: Negative\n",
      "Base Sentiment Score: 0.26\n",
      "Sentences sorted by their impact on the overall sentiment score:\n",
      "  [Impact: 0.2218] But at least there's enough neat carnival themes and b-movie monster makeup to keep you watching.\"\n",
      "  [Impact: 0.1323] Someone else called this film a \\fable-horror\\\" movie, and I think that fits pretty well.\n",
      "  [Impact: 0.1254] If you're into cheesy spookfests, you should have a laugh watching this one.\n",
      "  [Impact: 0.0951] That's the concept at least.\n",
      "  [Impact: 0.0841] The fate for some of the teens is shoved in your face too obviously, while other characters could have been fleshed out more.\n",
      "  [Impact: 0.0746] No resolution or big twist or anything.\n",
      "  [Impact: 0.0499] A cool idea, but could have been executed better.\n",
      "  [Impact: 0.0409] He decides to teach the teens a lesson by making them part of the freak show.\n",
      "  [Impact: 0.0244] Also, the ending was a serious let down.\n",
      "  [Impact: 0.0025] A group of teenagers, each with their own vice, catch the eye of a twisted sideshow barker.\n",
      "  [Impact: -0.0114] <br /><br />But as a low budget horror movie, it's pretty fun to watch.\n",
      "  [Impact: -0.0233] I think one of it's faults though... that it takes itself too seriously.\n",
      "  [Impact: -0.0266] It's a silly movie, and if it was a little more self-aware when it comes to that, I think it would have been better.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print review details with sentences sorted by their leave-one-out impact\n",
    "for idx, row in selected_reviews.iterrows():\n",
    "    print(f\"Review {idx + 1}:\")\n",
    "    sentiment = \"Positive\" if row['sentiment'] == 1 else \"Negative\"\n",
    "    print(f\"Overall Sentiment: {sentiment}\")\n",
    "    print(f\"Base Sentiment Score: {row['full_review_score']:.2f}\")\n",
    "\n",
    "    # Pair sentences with their leave-one-out differences\n",
    "    sentences = row['sentences']\n",
    "    leave_one_out_differences = row['leave_one_out_differences']\n",
    "\n",
    "    # Ensure all impacts are floats\n",
    "    leave_one_out_differences = [float(impact) for impact in leave_one_out_differences]\n",
    "\n",
    "    # Pair sentences with their leave-one-out differences\n",
    "    sentence_analysis = list(zip(sentences, leave_one_out_differences))\n",
    "\n",
    "    # Sort sentences by their absolute impact (magnitude of difference)\n",
    "    sorted_sentences = sorted(sentence_analysis, key=lambda x: (x[1]), reverse=True)\n",
    "\n",
    "    print(\"Sentences sorted by their impact on the overall sentiment score:\")\n",
    "    for sentence, impact in sorted_sentences:\n",
    "        print(f\"  [Impact: {impact:.4f}] {sentence}\")\n",
    "\n",
    "    print(\"-\" * 50)  # Separator for readability\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
